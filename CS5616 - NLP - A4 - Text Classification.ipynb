{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5616 - NLP - A4 - Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 209338R - KATS Jayathilaka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing and downloading NLTK Library and importing all other libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `conda install -c conda-forge pyspellchecker`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `conda install -c anaconda spacy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk import pos_tag\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "import spacy\n",
    "import nltk\n",
    "import fasttext.util\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You have to change this directory according to your system. Otherwise, nltk.download() will always be invoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am KATS Jayathilaka - SINGHABAHU is my nickname\n",
    "NLTK_DATA_PATH_CHECK = '/home/singhabahu/nltk_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(NLTK_DATA_PATH_CHECK):\n",
    "    nltk.download()\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the special things we (husband and me...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the companies which organize shark fe...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDOTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it safe for female traveller to go alone to...</td>\n",
       "      <td>TGU</td>\n",
       "      <td>TGUHEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the best places around Cape Town for ...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the best places to stay for a family ...</td>\n",
       "      <td>ACM</td>\n",
       "      <td>ACMOTH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class1  class2\n",
       "0  What are the special things we (husband and me...    TTD  TTDSIG\n",
       "1  What are the companies which organize shark fe...    TTD  TTDOTH\n",
       "2  Is it safe for female traveller to go alone to...    TGU  TGUHEA\n",
       "3  What are the best places around Cape Town for ...    TTD  TTDSIG\n",
       "4  What are the best places to stay for a family ...    ACM  ACMOTH"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_file = open('5000TravelQuestionsDataset.csv', encoding=\"latin-1\")\n",
    "\n",
    "df = pd.read_csv(d_file, header=None)\n",
    "df.columns = ['text', 'class1', 'class2']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.Removing mistakenly entered `class1` and `class2` entries as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.1. Stripping trailing and leading whitespaces and linebreaks from `class1` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TGU      1217\n",
       "TTD      1139\n",
       "TRS      1011\n",
       "ACM       720\n",
       "FOD       521\n",
       "ENT       214\n",
       "WTH       172\n",
       "TGU\\n       3\n",
       "\\nENT       2\n",
       "TTD\\n       1\n",
       "Name: class1, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coarse classes\n",
    "df['class1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Has anyone planned a simple wedding by themsel...</td>\n",
       "      <td>TGU\\n</td>\n",
       "      <td>TGUPLN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>What are the Trans-Mongolian stop recommendati...</td>\n",
       "      <td>TGU\\n</td>\n",
       "      <td>TGUOTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>What is a good Civil Ceremony Venue for a wedd...</td>\n",
       "      <td>TGU\\n</td>\n",
       "      <td>TGUOTH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text class1  class2\n",
       "524   Has anyone planned a simple wedding by themsel...  TGU\\n  TGUPLN\n",
       "3145  What are the Trans-Mongolian stop recommendati...  TGU\\n  TGUOTH\n",
       "3333  What is a good Civil Ceremony Venue for a wedd...  TGU\\n  TGUOTH"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class1').get_group('TGU\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3750</th>\n",
       "      <td>What are the best areas of town this year for ...</td>\n",
       "      <td>\\nENT</td>\n",
       "      <td>ENTFES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3751</th>\n",
       "      <td>What to do on Riverwalk at Christmas time ?</td>\n",
       "      <td>\\nENT</td>\n",
       "      <td>ENTFES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text class1  class2\n",
       "3750  What are the best areas of town this year for ...  \\nENT  ENTFES\n",
       "3751        What to do on Riverwalk at Christmas time ?  \\nENT  ENTFES"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class1').get_group('\\nENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3710</th>\n",
       "      <td>what is the best Zoo in Denmark ?</td>\n",
       "      <td>TTD\\n</td>\n",
       "      <td>TTDSIG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   text class1  class2\n",
       "3710  what is the best Zoo in Denmark ?  TTD\\n  TTDSIG"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class1').get_group('TTD\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efc1bfd8820>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEUCAYAAADHgubDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXYklEQVR4nO3dfbRldX3f8fcnEPERBRkoMuigjg+AEnSkJrqsQlNItUKq1MEYJw2RaLE+JYsHbaTpWpOSmriqrbpK1YCtlU5EA6vGB0SN0So4IAIDspgKwoQJM2JUagwG/PaPvaccLvdh7j3n7ntmfu/XWrPOOb+99/l+98zcz9l3P51UFZKkNvzcSjcgSRqOoS9JDTH0Jakhhr4kNcTQl6SGGPqS1JB9V7qBhRx00EG1Zs2alW5DkvYoV1999feqatXM8akP/TVr1rB58+aVbkOS9ihJvjvbuLt3JKkhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqyIKhn+TDSXYkuWFk7F1Jvp3kuiSfTPK4kWnnJtma5OYkJ46MPzfJ9f209ybJ5FdHkjSf3bk460LgPwMfGRm7HDi3qu5L8ofAucDZSY4E1gNHAU8APp/kaVV1P/AB4Azg68CfAycBn57Uikij1pzzqbHf47bzXzqBTqTpsuCWflV9Gfj+jLHPVdV9/cuvA6v75ycDF1fVvVV1K7AVOC7JocD+VfW16r6q6yPAKZNaCUnS7pnEPv3f5IEt9sOAO0ambevHDuufzxyXJA1orNBP8g7gPuCju4Zmma3mGZ/rfc9IsjnJ5p07d47ToiRpxJJDP8kG4GXAr9UD366+DTh8ZLbVwJ39+OpZxmdVVRdU1bqqWrdq1UNuEidJWqIlhX6Sk4CzgZdX1d+OTLoMWJ9kvyRHAGuBq6pqO3BPkuf3Z+28Frh0zN4lSYu04Nk7ST4GvBg4KMk24Dy6s3X2Ay7vz7z8elW9vqq2JNkE3Ei32+fM/swdgDfQnQn0CLpjAJ65I0kDWzD0q+q0WYY/NM/8G4GNs4xvBo5eVHeSpInyilxJaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkN25y6YkjcW7nk4Pt/QlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDVkwdBP8uEkO5LcMDJ2YJLLk9zSPx4wMu3cJFuT3JzkxJHx5ya5vp/23iSZ/OpIkuazO1v6FwInzRg7B7iiqtYCV/SvSXIksB44ql/m/Un26Zf5AHAGsLb/M/M9JUnLbMEvRq+qLydZM2P4ZODF/fOLgC8BZ/fjF1fVvcCtSbYCxyW5Ddi/qr4GkOQjwCnAp8deA0nz8kvJNWqp+/QPqartAP3jwf34YcAdI/Nt68cO65/PHJckDWjSB3Jn209f84zP/ibJGUk2J9m8c+fOiTUnSa1baujfleRQgP5xRz++DTh8ZL7VwJ39+OpZxmdVVRdU1bqqWrdq1aoltihJmmmpoX8ZsKF/vgG4dGR8fZL9khxBd8D2qn4X0D1Jnt+ftfPakWUkSQNZ8EBuko/RHbQ9KMk24DzgfGBTktOB24FTAapqS5JNwI3AfcCZVXV//1ZvoDsT6BF0B3A9iCtJA9uds3dOm2PSCXPMvxHYOMv4ZuDoRXUnSZoor8iVpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkLFCP8lbk2xJckOSjyV5eJIDk1ye5Jb+8YCR+c9NsjXJzUlOHL99SdJiLDn0kxwGvAlYV1VHA/sA64FzgCuqai1wRf+aJEf2048CTgLen2Sf8dqXJC3GuLt39gUekWRf4JHAncDJwEX99IuAU/rnJwMXV9W9VXUrsBU4bsz6kqRFWHLoV9VfAX8E3A5sB35YVZ8DDqmq7f0824GD+0UOA+4YeYtt/dhDJDkjyeYkm3fu3LnUFiVJM4yze+cAuq33I4AnAI9K8pr5FpllrGabsaouqKp1VbVu1apVS21RkjTDOLt3/jFwa1XtrKq/Bz4B/BJwV5JDAfrHHf3824DDR5ZfTbc7SJI0kHFC/3bg+UkemSTACcBNwGXAhn6eDcCl/fPLgPVJ9ktyBLAWuGqM+pKkRdp3qQtW1ZVJPg5cA9wHfBO4AHg0sCnJ6XQfDKf2829Jsgm4sZ//zKq6f8z+JUmLsOTQB6iq84DzZgzfS7fVP9v8G4GN49SUJC2dV+RKUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGjLWxVl6wJpzPjXW8red/9IJdSJJc3NLX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkLFCP8njknw8ybeT3JTkF5McmOTyJLf0jweMzH9ukq1Jbk5y4vjtS5IWY9wt/fcAn6mqZwDHADcB5wBXVNVa4Ir+NUmOBNYDRwEnAe9Pss+Y9SVJi7Dk0E+yP/Ai4EMAVfXTqvoBcDJwUT/bRcAp/fOTgYur6t6quhXYChy31PqSpMUbZ0v/ycBO4E+SfDPJB5M8CjikqrYD9I8H9/MfBtwxsvy2fuwhkpyRZHOSzTt37hyjRUnSqHFCf1/gOcAHqupY4Mf0u3LmkFnGarYZq+qCqlpXVetWrVo1RouSpFHjhP42YFtVXdm//jjdh8BdSQ4F6B93jMx/+Mjyq4E7x6gvSVqkJYd+Vf01cEeSp/dDJwA3ApcBG/qxDcCl/fPLgPVJ9ktyBLAWuGqp9SVJi7fvmMv/a+CjSR4GfAf4l3QfJJuSnA7cDpwKUFVbkmyi+2C4Dzizqu4fs74kaRHGCv2quhZYN8ukE+aYfyOwcZyakqSl84pcSWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkPGvSJXeog153xqrOVvO/+lE+pE0kxu6UtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGjJ26CfZJ8k3k/yv/vWBSS5Pckv/eMDIvOcm2Zrk5iQnjltbkrQ4k9jSfzNw08jrc4ArqmotcEX/miRHAuuBo4CTgPcn2WcC9SVJu2ms0E+yGngp8MGR4ZOBi/rnFwGnjIxfXFX3VtWtwFbguHHqS5IWZ9wt/f8InAX8bGTskKraDtA/HtyPHwbcMTLftn7sIZKckWRzks07d+4cs0VJ0i5LDv0kLwN2VNXVu7vILGM124xVdUFVrauqdatWrVpqi5KkGfYdY9kXAC9P8k+BhwP7J/nvwF1JDq2q7UkOBXb0828DDh9ZfjVw5xj1JUmLtOQt/ao6t6pWV9UaugO0X6iq1wCXARv62TYAl/bPLwPWJ9kvyRHAWuCqJXcuSVq0cbb053I+sCnJ6cDtwKkAVbUlySbgRuA+4Myqun8Z6kuS5jCR0K+qLwFf6p/fDZwwx3wbgY2TqClJWjyvyJWkhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhiw59JMcnuSLSW5KsiXJm/vxA5NcnuSW/vGAkWXOTbI1yc1JTpzECkiSdt++Yyx7H/A7VXVNkscAVye5HPgN4IqqOj/JOcA5wNlJjgTWA0cBTwA+n+RpVXX/eKugXdac86mx3+O28186gU4kTaslb+lX1faquqZ/fg9wE3AYcDJwUT/bRcAp/fOTgYur6t6quhXYChy31PqSpMWbyD79JGuAY4ErgUOqajt0HwzAwf1shwF3jCy2rR+b7f3OSLI5yeadO3dOokVJEhMI/SSPBi4B3lJVP5pv1lnGarYZq+qCqlpXVetWrVo1bouSpN5YoZ/k5+kC/6NV9Yl++K4kh/bTDwV29OPbgMNHFl8N3DlOfUnS4oxz9k6ADwE3VdW7RyZdBmzon28ALh0ZX59kvyRHAGuBq5ZaX5K0eOOcvfMC4NeB65Nc24+9HTgf2JTkdOB24FSAqtqSZBNwI92ZP2d65o4kDWvJoV9VX2H2/fQAJ8yxzEZg41JrStKebqVPrfaKXElqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqyOChn+SkJDcn2ZrknKHrS1LLBg39JPsA7wN+BTgSOC3JkUP2IEktG3pL/zhga1V9p6p+ClwMnDxwD5LUrFTVcMWSVwInVdVv9a9/HfiHVfXGGfOdAZzRv3w6cPMYZQ8CvjfG8pMyDX1MQw8wHX1MQw8wHX1MQw8wHX1MQw8wmT6eVFWrZg7uO+abLlZmGXvIp05VXQBcMJGCyeaqWjeJ99rT+5iGHqalj2noYVr6mIYepqWPaehhufsYevfONuDwkdergTsH7kGSmjV06H8DWJvkiCQPA9YDlw3cgyQ1a9DdO1V1X5I3Ap8F9gE+XFVblrnsRHYTTcA09DENPcB09DENPcB09DENPcB09DENPcAy9jHogVxJ0sryilxJaoihL0kNMfQlqSFNhH6SC1e6h6G1uM6zSfKcGX+OTXL4wkvuGfUWI8mTkjx25PVLkrwnydv6s+mG7GVDkmuS/Lj/sznJa/f0WnuCoS/OWinPHqpQkn8+3/Sq+sRArQy2zgtJ8njg1cAz+qGbgI9V1d0DlP/jWcYO7EPutKq6dg+vtxibgF8FfpjkF4A/Bf49cAzwfuC3hmiiD9y3AG8DrqG7aPM5wLuSUFUf2RNrLbG/t803varePfGaLZy9k+TbwGnMfkUwVXXNBGv9DLi2/8OMmlVVvzmpWgv0Mdg6L9DHM4Ev0J2m+82+n2OBXwaOr6pvD9HHLH2tA95dVS/aG+vN0cN1VfXs/vkfAT+rqrOS/Bxw7a5pA/TxdWB9Vd02Y3wNcHFVPX9PrLUUSc4befnbwH8ZnV5Vvz/xmo2E/j10F4bNehuIqjp+grV+FXgV8FTgUrot2q2Tev9F9DHYOi/Qx8eBTVW1acb4K4BXV9UrhuhjNkmuqarn7K31Zql/fVU9a1cvwLlV9dn+9XUDhv6NVTXr3XXnmzbttcaV5JtVdexy12ll987WoUKuqj4JfDLJo+juIPrH/e6Nd1TVXwzRQ2+wdV7As6rqlTMHq+qSJH+wEg0BJDmEWe77tLfUm8MXkmwCtgMH0P0GRpJDgZ8O2MdPljht2muNa5D/H62E/kr4O+CHwI+AJwIPX9l2VsyPlzhtIpL8Jx76w3Qg8EvAm/f0eov0FrrfQg8FXlhVf9+P/wPgHQP28cwk180yHuDJe3CtPUIroX/WUIWSvIRuX/pxwOeB91TV5qHqjxhsnRdw8BwHqwI85Lavy2Dm330BdwNvq6ode0G93VbdvtyLZ5l0Hd19sIbyzL201qIluZ4HNhKeOvIBFbp/sonvcmtln/4XmftXp6qqEyZY62d0P0Rf6Ws+qG5VvWlStRboY7B1XqCP8+abvhwHqjS7JPsDZwKH0d3o8HLgjcDv0h3IHeQLjZJ8rqr+yd5WaymSPGm+6VX13YnXbCT0nzvL8PPptoZ3VNXzJljrN5hn31xVXTSpWgv0Mdg6T7MkJwOrq+p9/esreeA3jLOr6k/35HqL7O1S4G+ArwEn0O3Xfxjw5iFPJR3qgOXQtZZiJT6Umti9U1VX73qe5B8BvwfsB7y+qj494XIXA4+pqp2jg0kOptu/P4iB13leSX4FOJfue5ELuBH4w6r68wHKn8WDd13sBzwPeBTwJ3Tnqu/J9RbjySNn73yQ7puZnlhV9wzcx2Pnu55lwteyDFlrKYbYxfkgTYQ+QJIT6YLv74CNVfXFZSr1XuAzwMz/TL8MvBB4wzLVfYgB13m+Hl5Hd/7xWTywv3sdcH6S1f23pC2nh1XVHSOvv9JfFHZ3f4bVnl5vMXYduKWq7k9y6woEPsBjgZcx9zfpTTT0B6y1FIN/KLWye+cbdJ+o76L71fZBJnxx1nznBW+pqqMmVWuBPgZb5wX6uJHuTJHvzxh/PF0gLuuBtiRbq+qpc0z7P1X1lD253mL0x5v+766XwCOAv+WBg4b7D9THkD8Hg9VaiiR3013PM9f1NBO/mLOVLf0f0/1nf2X/Z1QBkzyffdYrYHtD3utoyHWeT2YGPkBV3Z3M91c1MVcmeV1V/dcHNZX8NnDVXlBvMb41Jfu3791Lay3Fd4e6Sn+XJkK/ql48YLkdSY6rqgf9gCc5Dtg5xzITN/A6z+dHSY6pqm+NDiY5Bhhi18JbgT9L8mq6e68APJduX/spe0G9xZiWX+uftZfWWoqn9LfouLaq7huiYCu7d86qqv/QPz919AyKJH9QVW+fYK3j6G5sdSGw62DqOuC1dPcAuXJStRboY7B1XqCPFwIfpTuIeTVd8DwP2AC8pqq+ssz1r6mq5yQ5ge5AMsCWqvrC3lBvMZJsA+a8gVctw829VrqPaVnnuSS5hO5iuWfQner9v4GvAl+b7TfkidRsJPT//z1PZt7/ZDnuh9Jfcv+vgKPpQm4LcAXwqqo6c5K15ulh0HVeoJdD6M4PP4pu99cW4H1V9dcD1B70lL1pPkUwyXbgA8x9E75BrpkYso9pWeeFpLsL6zq6K7d/sf/zg+W4N1ATu3d48D/4zH/8ie9Yrqq7gPOSHEt3de4G4EXAJZOuNY9B13nOJpInVtXtwDuHqjnDqjmuCAaWZUtv6HqLsb2q/t0K1t9lyD6mZZ0X8ghgf7qzjR4L3AlcvxyFWgn9muP5bK/HkuRpdOdpn0Z3+f3/pPuN6iWTrLMbBlvnBfwZ3f3LSXJJDX9XzX2ARzPcB93Q9RZjWnoaso9pWedZJbmA7jfge4Ar6XbvvLuq/ma5arYS+sck+RH9aWr9c/rXk74R2reBvwT+WfW3VE7y1gnX2B1DrvN8Rn/oVuIGV0Nv6U3zluUgt97YDUP2MS3rPJcn0h3kvwX4K2Ab8IPlLNhE6FfVPgOWewXdlv4Xk3yG7grdwbc2Bl7n+cz3G8cQhv67n9oty+U6MLhYQ/YxLes8l6o6Kd25y0fR7c//HeDoJN+nO5g7772rlqKJA7krob/68hS63TzHAxcBn6yqz61oYwNLcj/dNQOjFwPBQBcEJTlwyB/8oetp75FkNfACuvB/GfD4qnrcxOsY+ssvyYHAqXRn70zDF5tImgJJ3kQX8i+gu03GV+muoP8qcH1V/WziNQ19SVoZSd5Nf25+VW0fpKahL0ntGPJeMJKkFWboS1JDDH1phiT/NsnvTvD9PpxkR5IbJvWe0lIZ+tLyuxA4aaWbkMDQl0jy2iTXJflWkv82Y9rrknyjn3ZJkkf246cmuaEf/3I/dlSSq5Jc27/fWoCq+jLgufuaCoa+mpbkKOAdwPFVdQzw5hmzfKKqntdPuwk4vR9/J3BiP/7yfuz1wHuq6hfo7pi4bdlXQFokQ1+tOx74eFV9D2a9bP/oJH+Z5Hrg1+gul4fu4pkL++8A3nXLi68Bb09yNvCkqvrJ8rcvLY6hr9aF+e8JdCHwxqp6FvD79Derq6rXA/8GOBy4Nsnjq+p/0G31/wT4bBKvvtbUMfTVuiuAf9F/UfuuW2aMegywPcnP023p08/3lKq6sqreCXwPODzJk4HvVNV7gcuAZw+yBtIiGPpqWlVtATYCf5HkWzz0q/V+j+4+55fT3TZ7l3club4/DfPLwLeAVwE3JLmW7uvvPgKQ5GN0u36enmRbktORVoi3YZCkhrilL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWrI/wPiPaDCU/j1WAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('class1').text.count().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class1'] = df['class1'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now there are exactly 7 coarse classes visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TGU    1220\n",
       "TTD    1140\n",
       "TRS    1011\n",
       "ACM     720\n",
       "FOD     521\n",
       "ENT     216\n",
       "WTH     172\n",
       "Name: class1, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efc1bd83be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('class1').text.count().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2. Stripping trailing and leading whitespaces and linebreaks from `class2` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TTDSIG      511\n",
       "ACMHOT      342\n",
       "TTDSPO      233\n",
       "FODBAK      221\n",
       "ACMOTH      207\n",
       "           ... \n",
       "\\nWTHOTH      1\n",
       "ACMOTH\\n      1\n",
       "TTDSPO\\n      1\n",
       "TRSROU\\n      1\n",
       "TGUCIG\\n      1\n",
       "Name: class2, Length: 79, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine classes\n",
    "df['class2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Can you suggest your favorite food stands for ...</td>\n",
       "      <td>FOD</td>\n",
       "      <td>FODBAK\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text class1    class2\n",
       "760  Can you suggest your favorite food stands for ...    FOD  FODBAK\\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class2').get_group('FODBAK\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>Where in Taormina can you watch Premier League...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSPO\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text class1    class2\n",
       "3429  Where in Taormina can you watch Premier League...    TTD  TTDSPO\\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class2').get_group('TTDSPO\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>What are the recommended reasonable accomodati...</td>\n",
       "      <td>ACM</td>\n",
       "      <td>ACMOTH\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text class1    class2\n",
       "3567  What are the recommended reasonable accomodati...    ACM  ACMOTH\\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class2').get_group('ACMOTH\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>What sites and places and activities are achie...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text class1    class2\n",
       "2601  What sites and places and activities are achie...    TTD  TTDSIG\\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class2').get_group('TTDSIG\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>How is the weather in october in hampton?</td>\n",
       "      <td>WTH</td>\n",
       "      <td>\\nWTHOTH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text class1    class2\n",
       "4926  How is the weather in october in hampton?    WTH  \\nWTHOTH"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class2').get_group('\\nWTHOTH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There are other mistakenly entered entries as well because here there are only 5 wrong groups from 79. But, there should be only 63 fine class labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class2'] = df['class2'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now there are only 63 fine classes visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TTDSIG    512\n",
       "ACMHOT    342\n",
       "TRSOTH    242\n",
       "TTDSPO    234\n",
       "FODBAK    222\n",
       "         ... \n",
       "ACMCAR      5\n",
       "ACMBEA      5\n",
       "TRSLIC      4\n",
       "TGURES      3\n",
       "TRSGAS      2\n",
       "Name: class2, Length: 63, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7efc1bd73ca0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('class2').text.count().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Advanced Preprocessing Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1. Removing numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       What are the special things we (husband and me...\n",
       "1       What are the companies which organize shark fe...\n",
       "2       Is it safe for female traveller to go alone to...\n",
       "3       What are the best places around Cape Town for ...\n",
       "4       What are the best places to stay for a family ...\n",
       "                              ...                        \n",
       "4995    What is the best area to be based for sightsee...\n",
       "4996    What are the good value traditional bars and r...\n",
       "4997       What are the hotels near Alicante bus station?\n",
       "4998       Where to stay in La Gomera to mountain biking?\n",
       "4999    Is it possible to take a train trip from Santi...\n",
       "Name: preprocessed_text, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "df['preprocessed_text'] = df['text'].apply(remove_numbers)\n",
    "df['preprocessed_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2. Removing punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       What are the special things we husband and me ...\n",
       "1       What are the companies which organize shark fe...\n",
       "2       Is it safe for female traveller to go alone to...\n",
       "3       What are the best places around Cape Town for ...\n",
       "4       What are the best places to stay for a family ...\n",
       "                              ...                        \n",
       "4995    What is the best area to be based for sightsee...\n",
       "4996    What are the good value traditional bars and r...\n",
       "4997        What are the hotels near Alicante bus station\n",
       "4998        Where to stay in La Gomera to mountain biking\n",
       "4999    Is it possible to take a train trip from Santi...\n",
       "Name: preprocessed_text, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preprocessed_text'] = df['preprocessed_text'].str.translate(str.maketrans('','', string.punctuation))\n",
    "df['preprocessed_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.3. Removing leading and trailing white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       What are the special things we husband and me ...\n",
       "1       What are the companies which organize shark fe...\n",
       "2       Is it safe for female traveller to go alone to...\n",
       "3       What are the best places around Cape Town for ...\n",
       "4       What are the best places to stay for a family ...\n",
       "                              ...                        \n",
       "4995    What is the best area to be based for sightsee...\n",
       "4996    What are the good value traditional bars and r...\n",
       "4997        What are the hotels near Alicante bus station\n",
       "4998        Where to stay in La Gomera to mountain biking\n",
       "4999    Is it possible to take a train trip from Santi...\n",
       "Name: preprocessed_text, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preprocessed_text'] = df['preprocessed_text'].str.strip()\n",
    "df['preprocessed_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.4. Converting to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       what are the special things we husband and me ...\n",
       "1       what are the companies which organize shark fe...\n",
       "2       is it safe for female traveller to go alone to...\n",
       "3       what are the best places around cape town for ...\n",
       "4       what are the best places to stay for a family ...\n",
       "                              ...                        \n",
       "4995    what is the best area to be based for sightsee...\n",
       "4996    what are the good value traditional bars and r...\n",
       "4997        what are the hotels near alicante bus station\n",
       "4998        where to stay in la gomera to mountain biking\n",
       "4999    is it possible to take a train trip from santi...\n",
       "Name: preprocessed_text, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preprocessed_text'] = df['preprocessed_text'].str.lower()\n",
    "df['preprocessed_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.5. Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               special things husband day stay cape town\n",
       "1       companies organize shark feeding events scuba ...\n",
       "2                safe female traveller go alone cape town\n",
       "3                     best places around cape town safari\n",
       "4             best places stay family stay away nightlife\n",
       "                              ...                        \n",
       "4995                    best area based sightseeing palma\n",
       "4996    good value traditional bars restaurants barcelona\n",
       "4997                     hotels near alicante bus station\n",
       "4998                       stay la gomera mountain biking\n",
       "4999             possible take train trip santiago madrid\n",
       "Name: preprocessed_text, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_english_stop_words(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered_words = [token for token in tokens if not token in stopwords.words('english')]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df['preprocessed_text'] = df['preprocessed_text'].apply(remove_english_stop_words)\n",
    "df['preprocessed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the special things we (husband and me...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "      <td>special things husband day stay cape town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the companies which organize shark fe...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDOTH</td>\n",
       "      <td>companies organize shark feeding events scuba ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it safe for female traveller to go alone to...</td>\n",
       "      <td>TGU</td>\n",
       "      <td>TGUHEA</td>\n",
       "      <td>safe female traveller go alone cape town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the best places around Cape Town for ...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "      <td>best places around cape town safari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the best places to stay for a family ...</td>\n",
       "      <td>ACM</td>\n",
       "      <td>ACMOTH</td>\n",
       "      <td>best places stay family stay away nightlife</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class1  class2  \\\n",
       "0  What are the special things we (husband and me...    TTD  TTDSIG   \n",
       "1  What are the companies which organize shark fe...    TTD  TTDOTH   \n",
       "2  Is it safe for female traveller to go alone to...    TGU  TGUHEA   \n",
       "3  What are the best places around Cape Town for ...    TTD  TTDSIG   \n",
       "4  What are the best places to stay for a family ...    ACM  ACMOTH   \n",
       "\n",
       "                                   preprocessed_text  \n",
       "0          special things husband day stay cape town  \n",
       "1  companies organize shark feeding events scuba ...  \n",
       "2           safe female traveller go alone cape town  \n",
       "3                best places around cape town safari  \n",
       "4        best places stay family stay away nightlife  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.6. Spell Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS DONE TO STOP THE REPEATED RUNNING OF THE SPELL CORRECTION WHICH TAKES NEARLY 20 MINUTES FOR THE DATASET\n",
    "DO_SPELL_CORRECTION = False\n",
    "\n",
    "ENTRY_SIZE_FOR_CLARITY = 10\n",
    "spc = SpellChecker()\n",
    "def spell_correction(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    spell_corrected_tokens = [spc.correction(token) for token in tokens]\n",
    "    return ' '.join(spell_corrected_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_SPELL_CORRECTION:\n",
    "    TOTAL_ENTRIES = df.shape[0]\n",
    "    start = time.time()\n",
    "    for i in range(TOTAL_ENTRIES):\n",
    "        df['preprocessed_text'][i] = spell_correction(df['preprocessed_text'][i])\n",
    "        if i % ENTRY_SIZE_FOR_CLARITY == 0 and i != 0:\n",
    "            print(f'[{i}/{TOTAL_ENTRIES}] entries checked and corrected. Elapsed Time: {round(time.time() - start, 2)} seconds ', end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.7. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              special things husband day stay cape town\n",
       "1        company organize shark feed events scuba divers\n",
       "2               safe female traveller go alone cape town\n",
       "3                     best place around cape town safari\n",
       "4             best place stay family stay away nightlife\n",
       "                              ...                       \n",
       "4995                       best area base sightsee palma\n",
       "4996    good value traditional bar restaurants barcelona\n",
       "4997                    hotels near alicante bus station\n",
       "4998                        stay la gomera mountain bike\n",
       "4999            possible take train trip santiago madrid\n",
       "Name: lemmatized, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "  lemmatized = [lemmatizer.lemmatize(word, pos=wordnet.VERB) for word in nltk.word_tokenize(text)]\n",
    "  return ' '.join(lemmatized)\n",
    "\n",
    "df['lemmatized'] = df['preprocessed_text'].apply(lemmatize_text)\n",
    "df['lemmatized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the special things we (husband and me...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "      <td>special things husband day stay cape town</td>\n",
       "      <td>special things husband day stay cape town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the companies which organize shark fe...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDOTH</td>\n",
       "      <td>companies organize shark feeding events scuba ...</td>\n",
       "      <td>company organize shark feed events scuba divers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it safe for female traveller to go alone to...</td>\n",
       "      <td>TGU</td>\n",
       "      <td>TGUHEA</td>\n",
       "      <td>safe female traveller go alone cape town</td>\n",
       "      <td>safe female traveller go alone cape town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the best places around Cape Town for ...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "      <td>best places around cape town safari</td>\n",
       "      <td>best place around cape town safari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the best places to stay for a family ...</td>\n",
       "      <td>ACM</td>\n",
       "      <td>ACMOTH</td>\n",
       "      <td>best places stay family stay away nightlife</td>\n",
       "      <td>best place stay family stay away nightlife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>What is the best area to be based for sightsee...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "      <td>best area based sightseeing palma</td>\n",
       "      <td>best area base sightsee palma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>What are the good value traditional bars and r...</td>\n",
       "      <td>FOD</td>\n",
       "      <td>FODBAR</td>\n",
       "      <td>good value traditional bars restaurants barcelona</td>\n",
       "      <td>good value traditional bar restaurants barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>What are the hotels near Alicante bus station?</td>\n",
       "      <td>ACM</td>\n",
       "      <td>ACMHOT</td>\n",
       "      <td>hotels near alicante bus station</td>\n",
       "      <td>hotels near alicante bus station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Where to stay in La Gomera to mountain biking?</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSPO</td>\n",
       "      <td>stay la gomera mountain biking</td>\n",
       "      <td>stay la gomera mountain bike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Is it possible to take a train trip from Santi...</td>\n",
       "      <td>TRS</td>\n",
       "      <td>TRSTRN</td>\n",
       "      <td>possible take train trip santiago madrid</td>\n",
       "      <td>possible take train trip santiago madrid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text class1  class2  \\\n",
       "0     What are the special things we (husband and me...    TTD  TTDSIG   \n",
       "1     What are the companies which organize shark fe...    TTD  TTDOTH   \n",
       "2     Is it safe for female traveller to go alone to...    TGU  TGUHEA   \n",
       "3     What are the best places around Cape Town for ...    TTD  TTDSIG   \n",
       "4     What are the best places to stay for a family ...    ACM  ACMOTH   \n",
       "...                                                 ...    ...     ...   \n",
       "4995  What is the best area to be based for sightsee...    TTD  TTDSIG   \n",
       "4996  What are the good value traditional bars and r...    FOD  FODBAR   \n",
       "4997     What are the hotels near Alicante bus station?    ACM  ACMHOT   \n",
       "4998     Where to stay in La Gomera to mountain biking?    TTD  TTDSPO   \n",
       "4999  Is it possible to take a train trip from Santi...    TRS  TRSTRN   \n",
       "\n",
       "                                      preprocessed_text  \\\n",
       "0             special things husband day stay cape town   \n",
       "1     companies organize shark feeding events scuba ...   \n",
       "2              safe female traveller go alone cape town   \n",
       "3                   best places around cape town safari   \n",
       "4           best places stay family stay away nightlife   \n",
       "...                                                 ...   \n",
       "4995                  best area based sightseeing palma   \n",
       "4996  good value traditional bars restaurants barcelona   \n",
       "4997                   hotels near alicante bus station   \n",
       "4998                     stay la gomera mountain biking   \n",
       "4999           possible take train trip santiago madrid   \n",
       "\n",
       "                                            lemmatized  \n",
       "0            special things husband day stay cape town  \n",
       "1      company organize shark feed events scuba divers  \n",
       "2             safe female traveller go alone cape town  \n",
       "3                   best place around cape town safari  \n",
       "4           best place stay family stay away nightlife  \n",
       "...                                                ...  \n",
       "4995                     best area base sightsee palma  \n",
       "4996  good value traditional bar restaurants barcelona  \n",
       "4997                  hotels near alicante bus station  \n",
       "4998                      stay la gomera mountain bike  \n",
       "4999          possible take train trip santiago madrid  \n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. SVM Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1. Bag of Words (BoW) with lemmatized tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Already the lemmatization was done as a preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              special things husband day stay cape town\n",
       "1        company organize shark feed events scuba divers\n",
       "2               safe female traveller go alone cape town\n",
       "3                     best place around cape town safari\n",
       "4             best place stay family stay away nightlife\n",
       "                              ...                       \n",
       "4995                       best area base sightsee palma\n",
       "4996    good value traditional bar restaurants barcelona\n",
       "4997                    hotels near alicante bus station\n",
       "4998                        stay la gomera mountain bike\n",
       "4999            possible take train trip santiago madrid\n",
       "Name: lemmatized, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatized']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.2. POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       special_JJ things_NNS husband_NN day_NN stay_V...\n",
       "1       companies_NNS organize_VBP shark_JJ feeding_VB...\n",
       "2       safe_JJ female_NN traveller_NN go_VBP alone_RB...\n",
       "3       best_JJS places_NNS around_IN cape_NN town_NN ...\n",
       "4       best_JJS places_NNS stay_VBP family_NN stay_VB...\n",
       "                              ...                        \n",
       "4995    best_JJS area_NN based_VBN sightseeing_NN palm...\n",
       "4996    good_JJ value_NN traditional_JJ bars_NNS resta...\n",
       "4997     hotels_NNS near_IN alicante_JJ bus_NN station_NN\n",
       "4998       stay_NN la_RB gomera_VBD mountain_NN biking_NN\n",
       "4999    possible_JJ take_NN train_NN trip_NN santiago_...\n",
       "Name: pos_tagged, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pos_tagger(text):\n",
    "    pos_tagged = [tok_pos[0] + '_' + tok_pos[1] for tok_pos in pos_tag(nltk.word_tokenize(text), lang='eng')] \n",
    "    return ' '.join(pos_tagged)\n",
    "\n",
    "df['pos_tagged'] = df['preprocessed_text'].apply(pos_tagger)\n",
    "df['pos_tagged']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.3. Headword extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Install spaCy by: `conda install -c conda-forge spacy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Install the `en_core_web_sm` by: `pip3 install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0.tar.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Support from online resources\n",
    "##### `https://github.com/explosion/spaCy/issues/7453`\n",
    "##### `https://github.com/explosion/spaCy/issues/4577`\n",
    "##### `https://spacy.io/models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       stay things town\n",
       "1       events companies organize divers\n",
       "2                           traveller go\n",
       "3                                 places\n",
       "4                     stay places family\n",
       "                      ...               \n",
       "4995                    based area palma\n",
       "4996          barcelona restaurants bars\n",
       "4997                              hotels\n",
       "4998                         stay biking\n",
       "4999                    madrid trip take\n",
       "Name: headwords, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "def headword_tokenizer(text):\n",
    "    head_words = []\n",
    "    for token in nlp(text):\n",
    "        if token.dep_ == \"nsubj\" or token.dep_ == \"dobj\" or token.dep_ == \"aux\" or token.dep_ == \"ROOT\":\n",
    "            head_words.append(token.text)\n",
    "            head_words.append(token.head.text)\n",
    "    unique_hw = list(set(head_words))\n",
    "    return ' '.join(unique_hw)\n",
    "\n",
    "# headword_tokenizer(df['preprocessed_text'][0])\n",
    "df['headwords'] = df['preprocessed_text'].apply(headword_tokenizer)\n",
    "df['headwords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.4. Headword Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       second sec s sulfur S sulphur atomic_number_16...\n",
       "1       vitamin_E tocopherol E einsteinium Es E atomic...\n",
       "2       thymine T deoxythymidine_monophosphate T metri...\n",
       "3       phosphorus P atomic_number_15 P p liter litre ...\n",
       "4       second sec s sulfur S sulphur atomic_number_16...\n",
       "                              ...                        \n",
       "4995    bacillus B B-complex_vitamin B_complex vitamin...\n",
       "4996    bacillus B B-complex_vitamin B_complex vitamin...\n",
       "4997    hydrogen H atomic_number_1 henry H Planck's_co...\n",
       "4998    second sec s sulfur S sulphur atomic_number_16...\n",
       "4999    meter metre m molarity molar_concentration M t...\n",
       "Name: headwords_synonyms, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_syns = 2\n",
    "\n",
    "def wordnet_synonyms(keywords):\n",
    "  synonyms = []\n",
    "  for keyword in keywords:\n",
    "    count = 0\n",
    "    for synset in wordnet.synsets(keyword):\n",
    "      if count <= max_syns:\n",
    "        for lemma in synset.lemmas():\n",
    "          if count <= max_syns:\n",
    "            synonyms.append(lemma.name())\n",
    "          else: \n",
    "            break\n",
    "        count = count + 1\n",
    "      else:\n",
    "        break\n",
    "\n",
    "  unique_synonyms = list(set(synonyms))\n",
    "  return ' '.join(synonyms)\n",
    "\n",
    "df['headwords_synonyms'] = df['headwords'].apply(wordnet_synonyms)\n",
    "df['headwords_synonyms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.5. Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5 day_DATE Cape Town_LOC\n",
       "1                               \n",
       "2                  Cape Town_GPE\n",
       "3                  Cape Town_LOC\n",
       "4                               \n",
       "                  ...           \n",
       "4995                   Palma_GPE\n",
       "4996               Barcelona_GPE\n",
       "4997                Alicante_GPE\n",
       "4998               La Gomera_GPE\n",
       "4999                  Madrid_GPE\n",
       "Name: named_entities, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def named_entity_tokenizer(text):\n",
    "    named_entities = []\n",
    "    for ent in nlp(text).ents:\n",
    "      named_entities.append(ent.text + '_' + ent.label_)\n",
    "    return ' '.join(named_entities)\n",
    "\n",
    "df['named_entities'] = df['text'].apply(named_entity_tokenizer)\n",
    "df['named_entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>headwords</th>\n",
       "      <th>headwords_synonyms</th>\n",
       "      <th>named_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the special things we (husband and me...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "      <td>special things husband day stay cape town</td>\n",
       "      <td>special things husband day stay cape town</td>\n",
       "      <td>special_JJ things_NNS husband_NN day_NN stay_V...</td>\n",
       "      <td>stay things town</td>\n",
       "      <td>second sec s sulfur S sulphur atomic_number_16...</td>\n",
       "      <td>5 day_DATE Cape Town_LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the companies which organize shark fe...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDOTH</td>\n",
       "      <td>companies organize shark feeding events scuba ...</td>\n",
       "      <td>company organize shark feed events scuba divers</td>\n",
       "      <td>companies_NNS organize_VBP shark_JJ feeding_VB...</td>\n",
       "      <td>events companies organize divers</td>\n",
       "      <td>vitamin_E tocopherol E einsteinium Es E atomic...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it safe for female traveller to go alone to...</td>\n",
       "      <td>TGU</td>\n",
       "      <td>TGUHEA</td>\n",
       "      <td>safe female traveller go alone cape town</td>\n",
       "      <td>safe female traveller go alone cape town</td>\n",
       "      <td>safe_JJ female_NN traveller_NN go_VBP alone_RB...</td>\n",
       "      <td>traveller go</td>\n",
       "      <td>thymine T deoxythymidine_monophosphate T metri...</td>\n",
       "      <td>Cape Town_GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the best places around Cape Town for ...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "      <td>best places around cape town safari</td>\n",
       "      <td>best place around cape town safari</td>\n",
       "      <td>best_JJS places_NNS around_IN cape_NN town_NN ...</td>\n",
       "      <td>places</td>\n",
       "      <td>phosphorus P atomic_number_15 P p liter litre ...</td>\n",
       "      <td>Cape Town_LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the best places to stay for a family ...</td>\n",
       "      <td>ACM</td>\n",
       "      <td>ACMOTH</td>\n",
       "      <td>best places stay family stay away nightlife</td>\n",
       "      <td>best place stay family stay away nightlife</td>\n",
       "      <td>best_JJS places_NNS stay_VBP family_NN stay_VB...</td>\n",
       "      <td>stay places family</td>\n",
       "      <td>second sec s sulfur S sulphur atomic_number_16...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>What is the best area to be based for sightsee...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "      <td>best area based sightseeing palma</td>\n",
       "      <td>best area base sightsee palma</td>\n",
       "      <td>best_JJS area_NN based_VBN sightseeing_NN palm...</td>\n",
       "      <td>based area palma</td>\n",
       "      <td>bacillus B B-complex_vitamin B_complex vitamin...</td>\n",
       "      <td>Palma_GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>What are the good value traditional bars and r...</td>\n",
       "      <td>FOD</td>\n",
       "      <td>FODBAR</td>\n",
       "      <td>good value traditional bars restaurants barcelona</td>\n",
       "      <td>good value traditional bar restaurants barcelona</td>\n",
       "      <td>good_JJ value_NN traditional_JJ bars_NNS resta...</td>\n",
       "      <td>barcelona restaurants bars</td>\n",
       "      <td>bacillus B B-complex_vitamin B_complex vitamin...</td>\n",
       "      <td>Barcelona_GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>What are the hotels near Alicante bus station?</td>\n",
       "      <td>ACM</td>\n",
       "      <td>ACMHOT</td>\n",
       "      <td>hotels near alicante bus station</td>\n",
       "      <td>hotels near alicante bus station</td>\n",
       "      <td>hotels_NNS near_IN alicante_JJ bus_NN station_NN</td>\n",
       "      <td>hotels</td>\n",
       "      <td>hydrogen H atomic_number_1 henry H Planck's_co...</td>\n",
       "      <td>Alicante_GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Where to stay in La Gomera to mountain biking?</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSPO</td>\n",
       "      <td>stay la gomera mountain biking</td>\n",
       "      <td>stay la gomera mountain bike</td>\n",
       "      <td>stay_NN la_RB gomera_VBD mountain_NN biking_NN</td>\n",
       "      <td>stay biking</td>\n",
       "      <td>second sec s sulfur S sulphur atomic_number_16...</td>\n",
       "      <td>La Gomera_GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Is it possible to take a train trip from Santi...</td>\n",
       "      <td>TRS</td>\n",
       "      <td>TRSTRN</td>\n",
       "      <td>possible take train trip santiago madrid</td>\n",
       "      <td>possible take train trip santiago madrid</td>\n",
       "      <td>possible_JJ take_NN train_NN trip_NN santiago_...</td>\n",
       "      <td>madrid trip take</td>\n",
       "      <td>meter metre m molarity molar_concentration M t...</td>\n",
       "      <td>Madrid_GPE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text class1  class2  \\\n",
       "0     What are the special things we (husband and me...    TTD  TTDSIG   \n",
       "1     What are the companies which organize shark fe...    TTD  TTDOTH   \n",
       "2     Is it safe for female traveller to go alone to...    TGU  TGUHEA   \n",
       "3     What are the best places around Cape Town for ...    TTD  TTDSIG   \n",
       "4     What are the best places to stay for a family ...    ACM  ACMOTH   \n",
       "...                                                 ...    ...     ...   \n",
       "4995  What is the best area to be based for sightsee...    TTD  TTDSIG   \n",
       "4996  What are the good value traditional bars and r...    FOD  FODBAR   \n",
       "4997     What are the hotels near Alicante bus station?    ACM  ACMHOT   \n",
       "4998     Where to stay in La Gomera to mountain biking?    TTD  TTDSPO   \n",
       "4999  Is it possible to take a train trip from Santi...    TRS  TRSTRN   \n",
       "\n",
       "                                      preprocessed_text  \\\n",
       "0             special things husband day stay cape town   \n",
       "1     companies organize shark feeding events scuba ...   \n",
       "2              safe female traveller go alone cape town   \n",
       "3                   best places around cape town safari   \n",
       "4           best places stay family stay away nightlife   \n",
       "...                                                 ...   \n",
       "4995                  best area based sightseeing palma   \n",
       "4996  good value traditional bars restaurants barcelona   \n",
       "4997                   hotels near alicante bus station   \n",
       "4998                     stay la gomera mountain biking   \n",
       "4999           possible take train trip santiago madrid   \n",
       "\n",
       "                                            lemmatized  \\\n",
       "0            special things husband day stay cape town   \n",
       "1      company organize shark feed events scuba divers   \n",
       "2             safe female traveller go alone cape town   \n",
       "3                   best place around cape town safari   \n",
       "4           best place stay family stay away nightlife   \n",
       "...                                                ...   \n",
       "4995                     best area base sightsee palma   \n",
       "4996  good value traditional bar restaurants barcelona   \n",
       "4997                  hotels near alicante bus station   \n",
       "4998                      stay la gomera mountain bike   \n",
       "4999          possible take train trip santiago madrid   \n",
       "\n",
       "                                             pos_tagged  \\\n",
       "0     special_JJ things_NNS husband_NN day_NN stay_V...   \n",
       "1     companies_NNS organize_VBP shark_JJ feeding_VB...   \n",
       "2     safe_JJ female_NN traveller_NN go_VBP alone_RB...   \n",
       "3     best_JJS places_NNS around_IN cape_NN town_NN ...   \n",
       "4     best_JJS places_NNS stay_VBP family_NN stay_VB...   \n",
       "...                                                 ...   \n",
       "4995  best_JJS area_NN based_VBN sightseeing_NN palm...   \n",
       "4996  good_JJ value_NN traditional_JJ bars_NNS resta...   \n",
       "4997   hotels_NNS near_IN alicante_JJ bus_NN station_NN   \n",
       "4998     stay_NN la_RB gomera_VBD mountain_NN biking_NN   \n",
       "4999  possible_JJ take_NN train_NN trip_NN santiago_...   \n",
       "\n",
       "                             headwords  \\\n",
       "0                     stay things town   \n",
       "1     events companies organize divers   \n",
       "2                         traveller go   \n",
       "3                               places   \n",
       "4                   stay places family   \n",
       "...                                ...   \n",
       "4995                  based area palma   \n",
       "4996        barcelona restaurants bars   \n",
       "4997                            hotels   \n",
       "4998                       stay biking   \n",
       "4999                  madrid trip take   \n",
       "\n",
       "                                     headwords_synonyms  \\\n",
       "0     second sec s sulfur S sulphur atomic_number_16...   \n",
       "1     vitamin_E tocopherol E einsteinium Es E atomic...   \n",
       "2     thymine T deoxythymidine_monophosphate T metri...   \n",
       "3     phosphorus P atomic_number_15 P p liter litre ...   \n",
       "4     second sec s sulfur S sulphur atomic_number_16...   \n",
       "...                                                 ...   \n",
       "4995  bacillus B B-complex_vitamin B_complex vitamin...   \n",
       "4996  bacillus B B-complex_vitamin B_complex vitamin...   \n",
       "4997  hydrogen H atomic_number_1 henry H Planck's_co...   \n",
       "4998  second sec s sulfur S sulphur atomic_number_16...   \n",
       "4999  meter metre m molarity molar_concentration M t...   \n",
       "\n",
       "                named_entities  \n",
       "0     5 day_DATE Cape Town_LOC  \n",
       "1                               \n",
       "2                Cape Town_GPE  \n",
       "3                Cape Town_LOC  \n",
       "4                               \n",
       "...                        ...  \n",
       "4995                 Palma_GPE  \n",
       "4996             Barcelona_GPE  \n",
       "4997              Alicante_GPE  \n",
       "4998             La Gomera_GPE  \n",
       "4999                Madrid_GPE  \n",
       "\n",
       "[5000 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.6. tf-idf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW vec shape: (5000, 1500)\n",
      "POS tagged: (5000, 1500)\n",
      "Head Words: (5000, 1500)\n",
      "Head Words Synonyms: (5000, 136)\n",
      "Named Entity: (5000, 1500)\n"
     ]
    }
   ],
   "source": [
    "def tfidf_vectorize(text):\n",
    "  tfidfconverter = TfidfVectorizer(max_features=1500, min_df=1, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "  vctzr = tfidfconverter.fit_transform(text).toarray()\n",
    "  return vctzr\n",
    "\n",
    "print('BoW vec shape:', tfidf_vectorize(df['lemmatized']).shape)\n",
    "print('POS tagged:', tfidf_vectorize(df['pos_tagged']).shape)\n",
    "print('Head Words:', tfidf_vectorize(df['headwords']).shape)\n",
    "print('Head Words Synonyms:', tfidf_vectorize(df['headwords_synonyms']).shape)\n",
    "print('Named Entity:', tfidf_vectorize(df['named_entities']).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.7. Label encoding for class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "x_encoded = np.concatenate(\n",
    "    (\n",
    "        tfidf_vectorize(df['lemmatized']), \n",
    "        tfidf_vectorize(df['pos_tagged']), \n",
    "        tfidf_vectorize(df['headwords']), \n",
    "        tfidf_vectorize(df['headwords_synonyms']), \n",
    "        tfidf_vectorize(df['named_entities'])\n",
    "    )\n",
    ", axis=1)\n",
    "y_encoded = le.fit_transform(df['class1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.8. SVM Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(encoded_x, encoded_y):\n",
    "  cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "  fold = 0\n",
    "  accuracies = []\n",
    "  for train_index, test_index in cv.split(x_encoded):\n",
    "      fold += 1\n",
    "      X_train, X_test = encoded_x[train_index], encoded_x[test_index]\n",
    "      y_train, y_test = encoded_y[train_index], encoded_y[test_index]\n",
    "      SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "      SVM.fit(X_train,y_train)\n",
    "      predictions = SVM.predict(X_test)\n",
    "      acc = accuracy_score(predictions, y_test)*100\n",
    "      accuracies.append(acc)\n",
    "      print(\"Fold: {} - {} - {:.2f}\".format(fold, \"Accuracy: \",acc))\n",
    "      \n",
    "  print(\"Mean {:.2f} Standard Deviation {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))\n",
    "\n",
    "  return predictions, y_test\n",
    "\n",
    "\n",
    "def accuracy_report(y_test, y_pred):\n",
    "    \n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred) * 100\n",
    "    print('Accuracy : %.3f' % acc)\n",
    "\n",
    "    f1 =  f1_score(y_test, y_pred, average='weighted')\n",
    "    print('F1 Score: %.3f' % f1)\n",
    "\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix: \\n{}\".format(cm))\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.9. Results for `class1` - All 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 - Accuracy:  - 78.80\n",
      "Fold: 2 - Accuracy:  - 78.20\n",
      "Fold: 3 - Accuracy:  - 76.20\n",
      "Fold: 4 - Accuracy:  - 77.00\n",
      "Fold: 5 - Accuracy:  - 77.20\n",
      "Fold: 6 - Accuracy:  - 78.00\n",
      "Fold: 7 - Accuracy:  - 79.80\n",
      "Fold: 8 - Accuracy:  - 78.20\n",
      "Fold: 9 - Accuracy:  - 77.60\n",
      "Fold: 10 - Accuracy:  - 80.00\n",
      "Mean 78.10 Standard Deviation 1.14\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_return = calculate_accuracy(x_encoded, y_encoded)\n",
    "print(f'Time: {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84        74\n",
      "           1       0.70      0.84      0.76        19\n",
      "           2       0.80      0.96      0.87        50\n",
      "           3       0.73      0.78      0.76       105\n",
      "           4       0.89      0.82      0.85       106\n",
      "           5       0.78      0.68      0.73       130\n",
      "           6       0.88      0.94      0.91        16\n",
      "\n",
      "    accuracy                           0.80       500\n",
      "   macro avg       0.80      0.84      0.82       500\n",
      "weighted avg       0.80      0.80      0.80       500\n",
      "\n",
      "Accuracy : 80.000\n",
      "F1 Score: 0.799\n",
      "Confusion Matrix: \n",
      "[[63  0  3  2  2  3  1]\n",
      " [ 0 16  0  1  0  2  0]\n",
      " [ 0  0 48  2  0  0  0]\n",
      " [ 4  2  3 82  3 10  1]\n",
      " [ 0  2  1  7 87  9  0]\n",
      " [ 9  3  5 18  6 89  0]\n",
      " [ 0  0  0  0  0  1 15]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7988413552946779"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_report(y_return[0], y_return[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.10. Label encoding for `class2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "x_encoded = np.concatenate(\n",
    "    (\n",
    "        tfidf_vectorize(df['lemmatized']), \n",
    "        tfidf_vectorize(df['pos_tagged']), \n",
    "        tfidf_vectorize(df['headwords']), \n",
    "        tfidf_vectorize(df['headwords_synonyms']), \n",
    "        tfidf_vectorize(df['named_entities'])\n",
    "    )\n",
    ", axis=1)\n",
    "y_encoded = le.fit_transform(df['class2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.11. Results for `class2` -  All 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 - Accuracy:  - 61.00\n",
      "Fold: 2 - Accuracy:  - 59.40\n",
      "Fold: 3 - Accuracy:  - 61.20\n",
      "Fold: 4 - Accuracy:  - 59.60\n",
      "Fold: 5 - Accuracy:  - 58.80\n",
      "Fold: 6 - Accuracy:  - 59.00\n",
      "Fold: 7 - Accuracy:  - 59.40\n",
      "Fold: 8 - Accuracy:  - 61.20\n",
      "Fold: 9 - Accuracy:  - 60.40\n",
      "Fold: 10 - Accuracy:  - 61.20\n",
      "Mean 60.12 Standard Deviation 0.93\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_return = calculate_accuracy(x_encoded, y_encoded)\n",
    "print(f'Time: {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           2       0.62      1.00      0.77         5\n",
      "           4       0.75      0.81      0.78        37\n",
      "           5       0.76      0.70      0.73        23\n",
      "           6       0.80      1.00      0.89         4\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.62      0.56      0.59         9\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         2\n",
      "          11       0.57      0.80      0.67         5\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.77      0.63      0.69        27\n",
      "          15       0.62      1.00      0.77        10\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.25      0.33      0.29         3\n",
      "          20       0.25      1.00      0.40         1\n",
      "          21       0.25      0.29      0.27         7\n",
      "          22       0.33      0.50      0.40         4\n",
      "          23       0.33      0.33      0.33         9\n",
      "          24       0.25      0.50      0.33         2\n",
      "          25       0.93      1.00      0.96        13\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       0.33      0.40      0.36        10\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       1.00      1.00      1.00         1\n",
      "          30       0.75      1.00      0.86         3\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.43      0.24      0.31        25\n",
      "          33       0.60      0.75      0.67         4\n",
      "          35       0.20      0.33      0.25         3\n",
      "          36       0.71      1.00      0.83         5\n",
      "          37       0.87      0.87      0.87        15\n",
      "          38       0.62      0.71      0.67         7\n",
      "          39       0.33      0.50      0.40         2\n",
      "          40       0.67      0.75      0.71         8\n",
      "          41       0.88      0.58      0.70        12\n",
      "          42       0.60      0.75      0.67         4\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          46       0.65      0.50      0.57        30\n",
      "          47       0.87      0.81      0.84        16\n",
      "          48       0.50      0.75      0.60         8\n",
      "          49       0.80      0.75      0.77        16\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       0.29      0.67      0.40         3\n",
      "          52       0.00      0.00      0.00         1\n",
      "          53       0.24      0.25      0.24        16\n",
      "          54       0.50      0.39      0.44        18\n",
      "          55       0.72      0.51      0.60        77\n",
      "          56       0.50      0.33      0.40         3\n",
      "          57       0.64      0.73      0.68        22\n",
      "          58       1.00      1.00      1.00         1\n",
      "          60       0.64      1.00      0.78         9\n",
      "          62       0.67      0.50      0.57         4\n",
      "\n",
      "    accuracy                           0.61       500\n",
      "   macro avg       0.49      0.55      0.51       500\n",
      "weighted avg       0.64      0.61      0.61       500\n",
      "\n",
      "Accuracy : 61.200\n",
      "F1 Score: 0.614\n",
      "Confusion Matrix: \n",
      "[[ 2  0  1 ...  0  0  0]\n",
      " [ 0  5  0 ...  0  0  0]\n",
      " [ 0  0 30 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  9  0]\n",
      " [ 0  0  0 ...  0  2  2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singhabahu/anaconda3/envs/python38test/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/singhabahu/anaconda3/envs/python38test/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6137680787439387"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_report(y_return[0], y_return[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.12. Results for `class1` - without `named_entities` feature (it results in records having NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "x_encoded_opt_ner = np.concatenate(\n",
    "    (\n",
    "        tfidf_vectorize(df['lemmatized']), \n",
    "        tfidf_vectorize(df['pos_tagged']), \n",
    "        tfidf_vectorize(df['headwords']), \n",
    "        tfidf_vectorize(df['headwords_synonyms']), \n",
    "    )\n",
    ", axis=1)\n",
    "x_encoded_opt_ner = le.fit_transform(df['class1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-fca61f3c09e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Time: {time.time() - start} seconds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-ffcc8bdb9c3e>\u001b[0m in \u001b[0;36mcalculate_accuracy\u001b[0;34m(encoded_x, encoded_y)\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mSVM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38test/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38test/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             self._probB, self.fit_status_ = libsvm.fit(\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_return = calculate_accuracy(x_encoded, y_encoded)\n",
    "print(f'Time: {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_report(y_return[0], y_return[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.13. Results for `class1` - BoW Feature only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "x_encoded = tfidf_vectorize(df['lemmatized'])\n",
    "y_encoded = le.fit_transform(df['class1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 - Accuracy:  - 82.80\n",
      "Fold: 2 - Accuracy:  - 81.40\n",
      "Fold: 3 - Accuracy:  - 78.80\n",
      "Fold: 4 - Accuracy:  - 79.60\n",
      "Fold: 5 - Accuracy:  - 80.20\n",
      "Fold: 6 - Accuracy:  - 79.80\n",
      "Fold: 7 - Accuracy:  - 82.00\n",
      "Fold: 8 - Accuracy:  - 81.20\n",
      "Fold: 9 - Accuracy:  - 81.00\n",
      "Fold: 10 - Accuracy:  - 80.80\n",
      "Mean 80.76 Standard Deviation 1.13\n",
      "Time: 414.49974274635315 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_return = calculate_accuracy(x_encoded, y_encoded)\n",
    "print(f'Time: {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84        72\n",
      "           1       0.65      0.94      0.77        16\n",
      "           2       0.82      0.94      0.87        52\n",
      "           3       0.73      0.79      0.76       104\n",
      "           4       0.91      0.82      0.86       109\n",
      "           5       0.82      0.70      0.75       133\n",
      "           6       0.82      1.00      0.90        14\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.79      0.86      0.82       500\n",
      "weighted avg       0.81      0.81      0.81       500\n",
      "\n",
      "Accuracy : 80.800\n",
      "F1 Score: 0.807\n",
      "Confusion Matrix: \n",
      "[[62  0  3  2  1  4  0]\n",
      " [ 0 15  0  0  0  1  0]\n",
      " [ 1  0 49  2  0  0  0]\n",
      " [ 3  1  4 82  4 10  0]\n",
      " [ 1  3  1  8 89  6  1]\n",
      " [ 9  4  3 18  4 93  2]\n",
      " [ 0  0  0  0  0  0 14]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8072469112763643"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_report(y_return[0], y_return[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.13. Results for `class2` - BoW Feature only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "x_encoded = tfidf_vectorize(df['lemmatized'])\n",
    "y_encoded = le.fit_transform(df['class2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 - Accuracy:  - 64.20\n",
      "Fold: 2 - Accuracy:  - 66.80\n",
      "Fold: 3 - Accuracy:  - 65.00\n",
      "Fold: 4 - Accuracy:  - 64.80\n",
      "Fold: 5 - Accuracy:  - 65.80\n",
      "Fold: 6 - Accuracy:  - 66.80\n",
      "Fold: 7 - Accuracy:  - 64.60\n",
      "Fold: 8 - Accuracy:  - 67.60\n",
      "Fold: 9 - Accuracy:  - 64.80\n",
      "Fold: 10 - Accuracy:  - 65.40\n",
      "Mean 65.58 Standard Deviation 1.07\n",
      "Time: 776.4438247680664 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_return = calculate_accuracy(x_encoded, y_encoded)\n",
    "print(f'Time: {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           2       0.62      1.00      0.77         5\n",
      "           4       0.72      0.83      0.77        35\n",
      "           5       0.81      0.71      0.76        24\n",
      "           6       0.80      1.00      0.89         4\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.62      0.83      0.71         6\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.86      1.00      0.92         6\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.82      0.67      0.73        27\n",
      "          15       0.81      1.00      0.90        13\n",
      "          16       0.00      0.00      0.00         4\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.25      1.00      0.40         1\n",
      "          20       0.25      1.00      0.40         1\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       0.50      0.50      0.50         6\n",
      "          23       0.44      0.67      0.53         6\n",
      "          24       0.25      0.50      0.33         2\n",
      "          25       1.00      1.00      1.00        14\n",
      "          26       1.00      1.00      1.00         2\n",
      "          27       0.42      1.00      0.59         5\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       1.00      1.00      1.00         1\n",
      "          30       1.00      1.00      1.00         4\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.43      0.55      0.48        11\n",
      "          33       1.00      0.71      0.83         7\n",
      "          35       0.20      0.25      0.22         4\n",
      "          36       0.86      1.00      0.92         6\n",
      "          37       0.80      0.80      0.80        15\n",
      "          38       0.88      0.88      0.88         8\n",
      "          39       0.33      0.50      0.40         2\n",
      "          40       0.56      0.83      0.67         6\n",
      "          41       0.75      0.55      0.63        11\n",
      "          42       0.80      0.57      0.67         7\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          46       0.65      0.54      0.59        28\n",
      "          47       0.93      0.82      0.87        17\n",
      "          48       0.50      0.60      0.55        10\n",
      "          49       0.93      0.82      0.87        17\n",
      "          50       1.00      1.00      1.00         2\n",
      "          51       0.57      0.67      0.62         6\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.18      0.27      0.21        11\n",
      "          54       0.64      0.64      0.64        14\n",
      "          55       0.83      0.41      0.55       109\n",
      "          56       0.50      1.00      0.67         1\n",
      "          57       0.52      0.68      0.59        19\n",
      "          58       1.00      1.00      1.00         1\n",
      "          60       0.71      0.91      0.80        11\n",
      "          62       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.65       500\n",
      "   macro avg       0.53      0.60      0.54       500\n",
      "weighted avg       0.72      0.65      0.67       500\n",
      "\n",
      "Accuracy : 65.400\n",
      "F1 Score: 0.666\n",
      "Confusion Matrix: \n",
      "[[ 2  0  0 ...  0  0  0]\n",
      " [ 0  5  0 ...  0  0  0]\n",
      " [ 0  0 29 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0 10  1]\n",
      " [ 0  0  0 ...  0  2  1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singhabahu/anaconda3/envs/python38test/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/singhabahu/anaconda3/envs/python38test/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.666165854064396"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_report(y_return[0], y_return[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. SVM Classifier with ‘fastText’ word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To install fasttext: `pip install fasttext` or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To install fasttext: `conda install -c conda-forge fasttext`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Download fasttext model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS ALREADY DOWNLOADED ONCE. HENCE, IT IS SKIPPED AS FOLLOWS.\n",
    "if False:\n",
    "    fasttext.util.download_model('en', if_exists='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "ft.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    temp = nlp(text)\n",
    "    return [str(token) for token in temp if not token.is_stop]\n",
    "\n",
    "tokenized = [tokenize(text) for text in df.lemmatized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(wordlist):\n",
    "  embedding=ft.get_sentence_vector(wordlist)\n",
    "  return embedding\n",
    "  \n",
    "embeddings = [np.mean(np.array(list(map(get_sentence_embedding,token))),axis=0) for token in tokenized]\n",
    "\n",
    "x_encoded = np.array(embeddings)\n",
    "x_encoded.shape\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_encoded_1 = le.fit_transform(df['class1'])\n",
    "y_encoded_2 = le.fit_transform(df['class2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1. Results for both classes `class1` and `class2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 - Accuracy:  - 78.80\n",
      "Fold: 2 - Accuracy:  - 77.40\n",
      "Fold: 3 - Accuracy:  - 77.40\n",
      "Fold: 4 - Accuracy:  - 77.40\n",
      "Fold: 5 - Accuracy:  - 78.60\n",
      "Fold: 6 - Accuracy:  - 78.00\n",
      "Fold: 7 - Accuracy:  - 76.60\n",
      "Fold: 8 - Accuracy:  - 79.80\n",
      "Fold: 9 - Accuracy:  - 78.20\n",
      "Fold: 10 - Accuracy:  - 79.60\n",
      "Mean 78.18 Standard Deviation 0.98\n",
      "Time: 63.84031057357788 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_return_1 = calculate_accuracy(x_encoded, y_encoded_1)\n",
    "print(f'Time: {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84        71\n",
      "           1       0.35      0.80      0.48        10\n",
      "           2       0.82      0.94      0.87        52\n",
      "           3       0.75      0.79      0.77       107\n",
      "           4       0.88      0.87      0.87        99\n",
      "           5       0.83      0.65      0.73       147\n",
      "           6       0.82      1.00      0.90        14\n",
      "\n",
      "    accuracy                           0.80       500\n",
      "   macro avg       0.75      0.85      0.78       500\n",
      "weighted avg       0.81      0.80      0.80       500\n",
      "\n",
      "Accuracy : 79.600\n",
      "F1 Score: 0.797\n",
      "Confusion Matrix: \n",
      "[[62  0  1  2  2  3  1]\n",
      " [ 0  8  1  0  1  0  0]\n",
      " [ 1  1 49  0  0  1  0]\n",
      " [ 6  2  2 84  3  9  1]\n",
      " [ 0  1  1  5 86  6  0]\n",
      " [ 7 11  6 21  6 95  1]\n",
      " [ 0  0  0  0  0  0 14]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7968300737168763"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_report(y_return_1[0], y_return_1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1 - Accuracy:  - 57.60\n",
      "Fold: 2 - Accuracy:  - 55.80\n",
      "Fold: 3 - Accuracy:  - 56.40\n",
      "Fold: 4 - Accuracy:  - 53.60\n",
      "Fold: 5 - Accuracy:  - 54.80\n",
      "Fold: 6 - Accuracy:  - 55.80\n",
      "Fold: 7 - Accuracy:  - 53.80\n",
      "Fold: 8 - Accuracy:  - 57.20\n",
      "Fold: 9 - Accuracy:  - 56.00\n",
      "Fold: 10 - Accuracy:  - 54.80\n",
      "Mean 55.58 Standard Deviation 1.26\n",
      "Time: 125.79759621620178 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "y_return_2 = calculate_accuracy(x_encoded, y_encoded_2)\n",
    "print(f'Time: {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.72      0.64      0.68        45\n",
      "           5       0.52      0.58      0.55        19\n",
      "           6       0.60      1.00      0.75         3\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.38      1.00      0.55         3\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         0\n",
      "          14       0.77      0.49      0.60        35\n",
      "          15       0.50      1.00      0.67         8\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.33      1.00      0.50         2\n",
      "          23       0.22      0.50      0.31         4\n",
      "          24       0.25      1.00      0.40         1\n",
      "          25       0.93      1.00      0.96        13\n",
      "          26       0.50      1.00      0.67         1\n",
      "          27       0.25      0.60      0.35         5\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.50      1.00      0.67         2\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.36      0.62      0.45         8\n",
      "          33       0.00      0.00      0.00         0\n",
      "          35       0.20      0.33      0.25         3\n",
      "          36       1.00      1.00      1.00         7\n",
      "          37       0.80      0.71      0.75        17\n",
      "          38       0.75      0.86      0.80         7\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.33      0.75      0.46         4\n",
      "          41       0.75      0.86      0.80         7\n",
      "          42       0.80      0.50      0.62         8\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          46       0.65      0.43      0.52        35\n",
      "          47       0.87      0.72      0.79        18\n",
      "          48       0.42      0.83      0.56         6\n",
      "          49       0.80      0.80      0.80        15\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.71      1.00      0.83         5\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.12      0.40      0.18         5\n",
      "          54       0.57      0.40      0.47        20\n",
      "          55       0.93      0.32      0.48       156\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.48      0.63      0.55        19\n",
      "          58       0.00      0.00      0.00         0\n",
      "          60       0.86      0.75      0.80        16\n",
      "          62       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.55       500\n",
      "   macro avg       0.34      0.42      0.35       500\n",
      "weighted avg       0.74      0.55      0.59       500\n",
      "\n",
      "Accuracy : 54.800\n",
      "F1 Score: 0.586\n",
      "Confusion Matrix: \n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 2  1 29 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0 12  3]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singhabahu/anaconda3/envs/python38test/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5856556661286672"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_report(y_return_2[0], y_return_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. LSTM Text Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.1. Label Encoding for both classes `class1` and `class2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To install keras: `conda install -c conda-forge keras`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_encoded_1 = le.fit_transform(df['class1'])\n",
    "y_encoded_2 = le.fit_transform(df['class2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 25)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 5000\n",
    "max_len = 25\n",
    "tok = Tokenizer(num_words=max_words, split=' ')\n",
    "tok.fit_on_texts(df['preprocessed_text'].values)\n",
    "seqs = tok.texts_to_sequences(df.lemmatized.values)\n",
    "seqs_mat = sequence.pad_sequences(seqs,maxlen=max_len)\n",
    "\n",
    "seqs_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.2. LSTM Network and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import SpatialDropout1D\n",
    "\n",
    "def MODEL_LSTM(num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(5000, 160, input_length=seqs_mat.shape[1]))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(196, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 7)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mat_1 = pd.get_dummies(df['class1']).values\n",
    "y_mat_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 63)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mat_2 = pd.get_dummies(df['class2']).values\n",
    "y_mat_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_lstm(seqs, seqs_mat, y_mat, num_classes):\n",
    "  cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "  fold = 0\n",
    "  accuracies = []\n",
    "  for train_index, test_index in cv.split(seqs):\n",
    "    fold += 1\n",
    "    X_train, X_test = seqs_mat[train_index], seqs_mat[test_index]\n",
    "    y_train, y_test = y_mat[train_index], y_mat[test_index]\n",
    "\n",
    "    model = MODEL_LSTM(num_classes)\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=64,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    fine_pred = [np.argmax(p) for p in predictions]\n",
    "    fine_gt = [np.argmax(p) for p in y_test]\n",
    "    f1 = accuracy_report(fine_pred, fine_gt)\n",
    "\n",
    "    accuracies.append(f1)\n",
    "    \n",
    "  print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.3. Results of LSTM for both classes `class1` and `class2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "64/64 [==============================] - 26s 399ms/step - loss: 1.7222 - accuracy: 0.2916 - val_loss: 1.9206 - val_accuracy: 0.1244\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 30s 462ms/step - loss: 0.9687 - accuracy: 0.6933 - val_loss: 1.2897 - val_accuracy: 0.5556\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 31s 485ms/step - loss: 0.4749 - accuracy: 0.8410 - val_loss: 0.8330 - val_accuracy: 0.7267\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 31s 477ms/step - loss: 0.2695 - accuracy: 0.9227 - val_loss: 1.0460 - val_accuracy: 0.7044\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 31s 479ms/step - loss: 0.1516 - accuracy: 0.9553 - val_loss: 0.9547 - val_accuracy: 0.7178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86        84\n",
      "           1       0.56      0.67      0.61        21\n",
      "           2       0.82      0.90      0.86        51\n",
      "           3       0.86      0.71      0.77       129\n",
      "           4       0.83      0.93      0.88        86\n",
      "           5       0.76      0.78      0.77       116\n",
      "           6       0.72      1.00      0.84        13\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.78      0.83      0.80       500\n",
      "weighted avg       0.82      0.81      0.81       500\n",
      "\n",
      "Accuracy : 81.000\n",
      "F1 Score: 0.809\n",
      "Confusion Matrix: \n",
      "[[71  0  2  5  1  5  0]\n",
      " [ 0 14  2  0  0  5  0]\n",
      " [ 1  3 46  1  0  0  0]\n",
      " [ 3  2  4 91 10 17  2]\n",
      " [ 1  1  0  3 80  1  0]\n",
      " [ 5  5  2  6  5 90  3]\n",
      " [ 0  0  0  0  0  0 13]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 28s 441ms/step - loss: 1.7424 - accuracy: 0.2998 - val_loss: 1.8015 - val_accuracy: 0.1644\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 30s 466ms/step - loss: 0.9935 - accuracy: 0.6738 - val_loss: 1.0880 - val_accuracy: 0.6244\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 30s 475ms/step - loss: 0.4427 - accuracy: 0.8546 - val_loss: 0.9289 - val_accuracy: 0.7089\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 31s 484ms/step - loss: 0.2275 - accuracy: 0.9338 - val_loss: 0.7146 - val_accuracy: 0.7711\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 30s 475ms/step - loss: 0.1214 - accuracy: 0.9664 - val_loss: 0.9294 - val_accuracy: 0.7044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.68      0.80       114\n",
      "           1       0.64      0.94      0.76        17\n",
      "           2       0.82      0.94      0.88        34\n",
      "           3       0.81      0.79      0.80       128\n",
      "           4       0.82      0.85      0.83        91\n",
      "           5       0.68      0.80      0.74        95\n",
      "           6       0.80      0.95      0.87        21\n",
      "\n",
      "    accuracy                           0.80       500\n",
      "   macro avg       0.79      0.85      0.81       500\n",
      "weighted avg       0.82      0.80      0.80       500\n",
      "\n",
      "Accuracy : 80.000\n",
      "F1 Score: 0.800\n",
      "Confusion Matrix: \n",
      "[[ 78   3   4  10   3  15   1]\n",
      " [  0  16   0   0   0   1   0]\n",
      " [  0   1  32   1   0   0   0]\n",
      " [  3   0   1 101  11  11   1]\n",
      " [  0   0   0   5  77   8   1]\n",
      " [  1   5   2   6   3  76   2]\n",
      " [  0   0   0   1   0   0  20]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 30s 469ms/step - loss: 1.7385 - accuracy: 0.2867 - val_loss: 1.8101 - val_accuracy: 0.1667\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 1.0197 - accuracy: 0.6728 - val_loss: 1.0571 - val_accuracy: 0.6667\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 31s 480ms/step - loss: 0.4679 - accuracy: 0.8578 - val_loss: 0.9705 - val_accuracy: 0.7067\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 32s 495ms/step - loss: 0.2545 - accuracy: 0.9210 - val_loss: 0.8065 - val_accuracy: 0.7489\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 31s 489ms/step - loss: 0.1368 - accuracy: 0.9654 - val_loss: 1.0549 - val_accuracy: 0.6911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82        74\n",
      "           1       0.81      0.50      0.62        26\n",
      "           2       0.87      0.80      0.83        56\n",
      "           3       0.76      0.69      0.72       140\n",
      "           4       0.89      0.82      0.85       106\n",
      "           5       0.62      0.87      0.72        85\n",
      "           6       0.75      0.92      0.83        13\n",
      "\n",
      "    accuracy                           0.77       500\n",
      "   macro avg       0.79      0.77      0.77       500\n",
      "weighted avg       0.79      0.77      0.77       500\n",
      "\n",
      "Accuracy : 77.400\n",
      "F1 Score: 0.774\n",
      "Confusion Matrix: \n",
      "[[60  0  2  7  1  4  0]\n",
      " [ 0 13  1  5  2  5  0]\n",
      " [ 4  1 45  1  0  4  1]\n",
      " [ 8  2  1 96  6 26  1]\n",
      " [ 0  0  2  9 87  7  1]\n",
      " [ 0  0  1  7  2 74  1]\n",
      " [ 0  0  0  1  0  0 12]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 29s 460ms/step - loss: 1.7179 - accuracy: 0.3059 - val_loss: 1.6730 - val_accuracy: 0.3689\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 30s 475ms/step - loss: 0.9610 - accuracy: 0.6946 - val_loss: 1.2148 - val_accuracy: 0.6111\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 31s 483ms/step - loss: 0.4633 - accuracy: 0.8570 - val_loss: 0.7845 - val_accuracy: 0.7400\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 0.2457 - accuracy: 0.9277 - val_loss: 0.8724 - val_accuracy: 0.7200\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 30s 473ms/step - loss: 0.1370 - accuracy: 0.9600 - val_loss: 0.8679 - val_accuracy: 0.7111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        75\n",
      "           1       0.38      0.82      0.51        11\n",
      "           2       0.89      0.89      0.89        57\n",
      "           3       0.78      0.72      0.75       134\n",
      "           4       0.84      0.84      0.84       102\n",
      "           5       0.75      0.75      0.75       106\n",
      "           6       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.79       500\n",
      "   macro avg       0.76      0.82      0.78       500\n",
      "weighted avg       0.81      0.79      0.80       500\n",
      "\n",
      "Accuracy : 79.400\n",
      "F1 Score: 0.797\n",
      "Confusion Matrix: \n",
      "[[60  3  1  7  2  2  0]\n",
      " [ 0  9  1  0  0  0  1]\n",
      " [ 1  2 51  0  0  3  0]\n",
      " [ 5  1  2 97 11 16  2]\n",
      " [ 1  0  0 10 86  5  0]\n",
      " [ 3  8  2 10  3 80  0]\n",
      " [ 0  1  0  0  0  0 14]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 33s 519ms/step - loss: 1.7320 - accuracy: 0.3104 - val_loss: 1.8085 - val_accuracy: 0.1933\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 32s 498ms/step - loss: 0.9899 - accuracy: 0.6706 - val_loss: 1.0250 - val_accuracy: 0.6444\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 38s 594ms/step - loss: 0.4473 - accuracy: 0.8598 - val_loss: 0.9585 - val_accuracy: 0.7156\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 32s 494ms/step - loss: 0.2364 - accuracy: 0.9336 - val_loss: 0.9474 - val_accuracy: 0.6867\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 32s 504ms/step - loss: 0.1476 - accuracy: 0.9607 - val_loss: 0.7974 - val_accuracy: 0.7422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        57\n",
      "           1       0.70      0.78      0.74        27\n",
      "           2       0.96      0.76      0.85        62\n",
      "           3       0.70      0.81      0.75       109\n",
      "           4       0.82      0.95      0.88        95\n",
      "           5       0.72      0.60      0.66       136\n",
      "           6       0.73      0.79      0.76        14\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.77      0.78      0.77       500\n",
      "weighted avg       0.77      0.76      0.76       500\n",
      "\n",
      "Accuracy : 76.400\n",
      "F1 Score: 0.761\n",
      "Confusion Matrix: \n",
      "[[43  1  0  4  1  8  0]\n",
      " [ 1 21  0  0  1  4  0]\n",
      " [ 2  1 47  3  1  7  1]\n",
      " [ 0  0  0 88  9 11  1]\n",
      " [ 0  0  1  4 90  0  0]\n",
      " [11  6  1 26  8 82  2]\n",
      " [ 0  1  0  0  0  2 11]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 34s 533ms/step - loss: 1.7471 - accuracy: 0.2889 - val_loss: 1.6905 - val_accuracy: 0.5911\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 33s 516ms/step - loss: 1.0045 - accuracy: 0.6807 - val_loss: 1.0685 - val_accuracy: 0.6889\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 36s 558ms/step - loss: 0.4702 - accuracy: 0.8432 - val_loss: 0.9742 - val_accuracy: 0.7289\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 33s 513ms/step - loss: 0.2489 - accuracy: 0.9257 - val_loss: 0.6639 - val_accuracy: 0.7933\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 31s 479ms/step - loss: 0.1784 - accuracy: 0.9519 - val_loss: 0.8528 - val_accuracy: 0.7422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81        57\n",
      "           1       0.71      0.59      0.65        17\n",
      "           2       0.90      0.85      0.87        53\n",
      "           3       0.78      0.81      0.79       144\n",
      "           4       0.91      0.85      0.88       117\n",
      "           5       0.72      0.77      0.74        95\n",
      "           6       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.81       500\n",
      "   macro avg       0.82      0.80      0.81       500\n",
      "weighted avg       0.82      0.81      0.81       500\n",
      "\n",
      "Accuracy : 81.400\n",
      "F1 Score: 0.815\n",
      "Confusion Matrix: \n",
      "[[ 47   1   0   6   0   3   0]\n",
      " [  1  10   1   0   2   3   0]\n",
      " [  2   0  45   2   2   2   0]\n",
      " [  4   0   3 116   4  17   0]\n",
      " [  2   0   0  11 100   3   1]\n",
      " [  3   3   1  13   1  73   1]\n",
      " [  0   0   0   0   1   0  16]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 29s 455ms/step - loss: 1.7136 - accuracy: 0.3049 - val_loss: 1.6897 - val_accuracy: 0.2444\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 39s 616ms/step - loss: 0.9758 - accuracy: 0.6864 - val_loss: 1.3043 - val_accuracy: 0.5711\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 38s 596ms/step - loss: 0.4984 - accuracy: 0.8383 - val_loss: 1.1061 - val_accuracy: 0.6511\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 37s 571ms/step - loss: 0.2778 - accuracy: 0.9168 - val_loss: 0.8707 - val_accuracy: 0.7200\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 34s 530ms/step - loss: 0.1477 - accuracy: 0.9598 - val_loss: 0.9635 - val_accuracy: 0.7044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84        73\n",
      "           1       0.40      0.62      0.49        16\n",
      "           2       0.91      0.75      0.82        52\n",
      "           3       0.83      0.67      0.74       136\n",
      "           4       0.90      0.83      0.86       106\n",
      "           5       0.69      0.77      0.73       108\n",
      "           6       0.60      1.00      0.75         9\n",
      "\n",
      "    accuracy                           0.78       500\n",
      "   macro avg       0.73      0.80      0.75       500\n",
      "weighted avg       0.79      0.78      0.78       500\n",
      "\n",
      "Accuracy : 77.600\n",
      "F1 Score: 0.778\n",
      "Confusion Matrix: \n",
      "[[68  0  0  2  0  2  1]\n",
      " [ 0 10  1  0  1  4  0]\n",
      " [ 2  4 39  2  0  5  0]\n",
      " [12  5  2 91  5 21  0]\n",
      " [ 3  1  0  7 88  5  2]\n",
      " [ 4  5  1  8  4 83  3]\n",
      " [ 0  0  0  0  0  0  9]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 34s 526ms/step - loss: 1.7429 - accuracy: 0.2817 - val_loss: 1.9208 - val_accuracy: 0.1244\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 38s 590ms/step - loss: 1.0367 - accuracy: 0.6598 - val_loss: 1.2446 - val_accuracy: 0.5800\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 37s 579ms/step - loss: 0.4607 - accuracy: 0.8536 - val_loss: 0.8189 - val_accuracy: 0.7267\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 36s 564ms/step - loss: 0.2585 - accuracy: 0.9235 - val_loss: 0.8081 - val_accuracy: 0.7533\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 33s 518ms/step - loss: 0.1467 - accuracy: 0.9578 - val_loss: 0.8002 - val_accuracy: 0.7467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.75      0.81        75\n",
      "           1       0.75      0.75      0.75        16\n",
      "           2       0.82      0.91      0.86        55\n",
      "           3       0.78      0.74      0.76       124\n",
      "           4       0.80      0.91      0.85        97\n",
      "           5       0.73      0.69      0.71       121\n",
      "           6       0.71      1.00      0.83        12\n",
      "\n",
      "    accuracy                           0.79       500\n",
      "   macro avg       0.78      0.82      0.80       500\n",
      "weighted avg       0.79      0.79      0.79       500\n",
      "\n",
      "Accuracy : 78.800\n",
      "F1 Score: 0.786\n",
      "Confusion Matrix: \n",
      "[[56  0  2  5  3  9  0]\n",
      " [ 0 12  1  1  0  2  0]\n",
      " [ 0  1 50  2  0  2  0]\n",
      " [ 2  1  3 92 12 14  0]\n",
      " [ 1  0  1  3 88  4  0]\n",
      " [ 4  2  4 15  7 84  5]\n",
      " [ 0  0  0  0  0  0 12]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 28s 444ms/step - loss: 1.7265 - accuracy: 0.2867 - val_loss: 1.5681 - val_accuracy: 0.6444\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 29s 451ms/step - loss: 1.0020 - accuracy: 0.6874 - val_loss: 1.2101 - val_accuracy: 0.5911\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 29s 455ms/step - loss: 0.4554 - accuracy: 0.8590 - val_loss: 0.9228 - val_accuracy: 0.7333\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 29s 460ms/step - loss: 0.2467 - accuracy: 0.9257 - val_loss: 0.9380 - val_accuracy: 0.6933\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 30s 470ms/step - loss: 0.1552 - accuracy: 0.9600 - val_loss: 0.8609 - val_accuracy: 0.7244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        71\n",
      "           1       0.50      0.64      0.56        14\n",
      "           2       0.93      0.89      0.91        56\n",
      "           3       0.81      0.72      0.76       143\n",
      "           4       0.87      0.88      0.88        94\n",
      "           5       0.70      0.79      0.74       108\n",
      "           6       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.80       500\n",
      "   macro avg       0.79      0.81      0.80       500\n",
      "weighted avg       0.81      0.80      0.80       500\n",
      "\n",
      "Accuracy : 80.200\n",
      "F1 Score: 0.803\n",
      "Confusion Matrix: \n",
      "[[ 58   0   2   4   1   6   0]\n",
      " [  1   9   0   0   0   4   0]\n",
      " [  0   3  50   2   0   1   0]\n",
      " [  6   2   2 103  10  20   0]\n",
      " [  1   0   0   6  83   4   0]\n",
      " [  5   4   0  12   1  85   1]\n",
      " [  0   0   0   0   0   1  13]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 29s 454ms/step - loss: 1.7157 - accuracy: 0.3077 - val_loss: 1.7810 - val_accuracy: 0.1333\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 35s 544ms/step - loss: 0.9706 - accuracy: 0.6815 - val_loss: 1.0131 - val_accuracy: 0.6844\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 35s 548ms/step - loss: 0.4894 - accuracy: 0.8407 - val_loss: 1.2827 - val_accuracy: 0.5844\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 34s 538ms/step - loss: 0.2883 - accuracy: 0.9168 - val_loss: 0.8798 - val_accuracy: 0.7267\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 31s 480ms/step - loss: 0.1624 - accuracy: 0.9536 - val_loss: 0.8336 - val_accuracy: 0.7444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83        78\n",
      "           1       0.57      0.76      0.65        17\n",
      "           2       0.82      0.84      0.83        58\n",
      "           3       0.69      0.83      0.75        93\n",
      "           4       0.96      0.82      0.88       115\n",
      "           5       0.79      0.72      0.75       125\n",
      "           6       0.82      1.00      0.90        14\n",
      "\n",
      "    accuracy                           0.80       500\n",
      "   macro avg       0.78      0.83      0.80       500\n",
      "weighted avg       0.81      0.80      0.80       500\n",
      "\n",
      "Accuracy : 80.200\n",
      "F1 Score: 0.804\n",
      "Confusion Matrix: \n",
      "[[64  0  6  2  1  5  0]\n",
      " [ 0 13  0  1  0  3  0]\n",
      " [ 2  3 49  3  0  1  0]\n",
      " [ 3  1  2 77  2  8  0]\n",
      " [ 0  1  0 12 94  7  1]\n",
      " [ 7  5  3 17  1 90  2]\n",
      " [ 0  0  0  0  0  0 14]]\n",
      "Mean 0.79 Std 0.02\n",
      "Time: 1706.2710523605347 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "evaluate_lstm(seqs, seqs_mat, y_mat_1, 7)\n",
    "print(f'Time: {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "64/64 [==============================] - 27s 417ms/step - loss: 3.7669 - accuracy: 0.0753 - val_loss: 3.4735 - val_accuracy: 0.1378\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 31s 478ms/step - loss: 3.6005 - accuracy: 0.1190 - val_loss: 3.2924 - val_accuracy: 0.2933\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 32s 506ms/step - loss: 2.7890 - accuracy: 0.3343 - val_loss: 2.4034 - val_accuracy: 0.4467\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 34s 535ms/step - loss: 1.7345 - accuracy: 0.5965 - val_loss: 2.0792 - val_accuracy: 0.5178\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 35s 552ms/step - loss: 1.1184 - accuracy: 0.7341 - val_loss: 2.0075 - val_accuracy: 0.5311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.88      0.76      0.81        46\n",
      "           5       0.77      0.74      0.76        23\n",
      "           6       1.00      0.41      0.58        17\n",
      "           7       0.33      1.00      0.50         2\n",
      "           8       0.62      0.42      0.50        12\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.25      1.00      0.40         1\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.80      0.71      0.75        28\n",
      "          15       0.75      0.38      0.50         8\n",
      "          16       0.25      1.00      0.40         1\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.67      1.00      0.80         2\n",
      "          19       0.14      1.00      0.25         1\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.14      0.07      0.09        15\n",
      "          22       0.50      0.50      0.50         2\n",
      "          23       0.12      0.11      0.12         9\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.75      0.67      0.71         9\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.56      0.45      0.50        11\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.67      1.00      0.80         2\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.68      0.45      0.55        33\n",
      "          33       0.33      1.00      0.50         1\n",
      "          35       0.25      0.12      0.17         8\n",
      "          36       0.91      1.00      0.95        10\n",
      "          37       0.71      0.55      0.62        22\n",
      "          38       1.00      0.73      0.84        11\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.83      0.83      0.83         6\n",
      "          41       0.75      1.00      0.86         9\n",
      "          42       0.75      0.50      0.60         6\n",
      "          46       0.58      0.67      0.62        21\n",
      "          47       0.78      0.78      0.78        18\n",
      "          48       0.67      0.73      0.70        11\n",
      "          49       0.82      0.64      0.72        14\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.75      0.67      0.71         9\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.42      0.24      0.30        21\n",
      "          54       0.81      0.71      0.76        24\n",
      "          55       0.69      0.65      0.67        52\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.58      0.82      0.68        17\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.87      0.76      0.81        17\n",
      "          61       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.62       500\n",
      "   macro avg       0.39      0.42      0.38       500\n",
      "weighted avg       0.70      0.62      0.64       500\n",
      "\n",
      "Accuracy : 61.600\n",
      "F1 Score: 0.642\n",
      "Confusion Matrix: \n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0 13  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 29s 461ms/step - loss: 3.7673 - accuracy: 0.0768 - val_loss: 3.4551 - val_accuracy: 0.3133\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 3.5853 - accuracy: 0.1242 - val_loss: 3.0878 - val_accuracy: 0.3044\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 31s 485ms/step - loss: 2.6453 - accuracy: 0.3736 - val_loss: 2.6049 - val_accuracy: 0.3933\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 32s 493ms/step - loss: 1.6103 - accuracy: 0.6195 - val_loss: 1.9716 - val_accuracy: 0.5356\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 30s 472ms/step - loss: 1.0229 - accuracy: 0.7533 - val_loss: 1.9333 - val_accuracy: 0.5311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singhabahu/anaconda3/envs/python38test/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.25      0.50      0.33         2\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.90      0.70      0.79        54\n",
      "           5       0.77      0.63      0.69        27\n",
      "           6       0.90      0.64      0.75        14\n",
      "           7       0.40      0.67      0.50         3\n",
      "           8       0.67      0.91      0.77        11\n",
      "           9       0.50      0.33      0.40         3\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.50      1.00      0.67         1\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.89      0.74      0.81        23\n",
      "          15       0.75      0.38      0.50         8\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.14      0.12      0.13         8\n",
      "          22       0.29      0.20      0.24        10\n",
      "          23       0.43      0.50      0.46        12\n",
      "          24       1.00      0.75      0.86         4\n",
      "          25       0.80      0.80      0.80        10\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.60      0.60      0.60        10\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.67      0.33      0.44         6\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.42      0.62      0.50        13\n",
      "          33       0.50      1.00      0.67         1\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.60      0.50      0.55         6\n",
      "          36       0.90      0.82      0.86        11\n",
      "          37       0.89      0.85      0.87        20\n",
      "          38       1.00      1.00      1.00         7\n",
      "          39       0.50      0.33      0.40         3\n",
      "          40       0.25      0.22      0.24         9\n",
      "          41       0.86      1.00      0.92         6\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.63      0.51      0.57        37\n",
      "          47       1.00      0.58      0.73        19\n",
      "          48       0.36      0.33      0.34        15\n",
      "          49       1.00      0.92      0.96        12\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.25      0.33      0.29         3\n",
      "          53       0.00      0.00      0.00         2\n",
      "          54       0.83      0.75      0.79        20\n",
      "          55       0.70      0.64      0.67        59\n",
      "          56       0.20      1.00      0.33         1\n",
      "          57       0.79      0.52      0.62        29\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.76      0.93      0.84        14\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.62       500\n",
      "   macro avg       0.41      0.40      0.39       500\n",
      "weighted avg       0.72      0.62      0.66       500\n",
      "\n",
      "Accuracy : 62.400\n",
      "F1 Score: 0.659\n",
      "Confusion Matrix: \n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  1  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 13  0  1]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 30s 466ms/step - loss: 3.7539 - accuracy: 0.0830 - val_loss: 3.4151 - val_accuracy: 0.3089\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 32s 493ms/step - loss: 3.5767 - accuracy: 0.1205 - val_loss: 3.2961 - val_accuracy: 0.2089\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 31s 485ms/step - loss: 2.6318 - accuracy: 0.3842 - val_loss: 2.2641 - val_accuracy: 0.4244\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 31s 484ms/step - loss: 1.6379 - accuracy: 0.6222 - val_loss: 1.9015 - val_accuracy: 0.5444\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 30s 468ms/step - loss: 1.0610 - accuracy: 0.7444 - val_loss: 1.8303 - val_accuracy: 0.5711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           2       0.25      1.00      0.40         1\n",
      "           4       0.83      0.71      0.76        34\n",
      "           5       0.57      0.77      0.65        22\n",
      "           6       0.67      0.80      0.73         5\n",
      "           7       0.43      1.00      0.60         3\n",
      "           8       0.75      0.50      0.60         6\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       1.00      0.17      0.29         6\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       0.79      0.79      0.79        33\n",
      "          15       0.50      0.50      0.50         2\n",
      "          16       1.00      0.25      0.40         4\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.17      0.17      0.17         6\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.33      0.25      0.29         8\n",
      "          24       0.25      0.33      0.29         3\n",
      "          25       1.00      0.83      0.91        12\n",
      "          26       1.00      0.33      0.50         3\n",
      "          27       0.59      0.45      0.51        29\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         0\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.47      0.50      0.48        16\n",
      "          33       0.00      0.00      0.00         2\n",
      "          35       0.14      0.17      0.15         6\n",
      "          36       0.80      0.67      0.73         6\n",
      "          37       0.95      0.77      0.85        26\n",
      "          38       0.50      0.62      0.56         8\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.40      1.00      0.57         2\n",
      "          41       0.82      0.82      0.82        11\n",
      "          42       0.50      0.50      0.50         6\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.59      0.45      0.51        29\n",
      "          47       1.00      0.94      0.97        18\n",
      "          48       0.47      1.00      0.64         7\n",
      "          49       0.91      0.67      0.77        15\n",
      "          50       0.50      1.00      0.67         2\n",
      "          51       0.67      0.80      0.73         5\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.16      0.25      0.19        12\n",
      "          54       0.76      0.84      0.80        19\n",
      "          55       0.70      0.44      0.54        80\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.57      0.38      0.46        34\n",
      "          58       0.00      0.00      0.00         0\n",
      "          60       0.75      0.86      0.80        14\n",
      "\n",
      "    accuracy                           0.59       500\n",
      "   macro avg       0.41      0.41      0.38       500\n",
      "weighted avg       0.68      0.59      0.61       500\n",
      "\n",
      "Accuracy : 58.800\n",
      "F1 Score: 0.611\n",
      "Confusion Matrix: \n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  1  0 ...  0  0  0]\n",
      " [ 0  1 24 ...  0  0  0]\n",
      " ...\n",
      " [ 0  1  0 ... 13  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0 12]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 31s 485ms/step - loss: 3.7524 - accuracy: 0.0854 - val_loss: 3.4838 - val_accuracy: 0.3133\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 3.6091 - accuracy: 0.1284 - val_loss: 3.3718 - val_accuracy: 0.2689\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 31s 478ms/step - loss: 2.7985 - accuracy: 0.3462 - val_loss: 2.3978 - val_accuracy: 0.4844\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 1.6748 - accuracy: 0.6062 - val_loss: 2.1025 - val_accuracy: 0.5244\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 31s 483ms/step - loss: 1.1139 - accuracy: 0.7319 - val_loss: 2.0698 - val_accuracy: 0.5178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40         1\n",
      "           2       0.20      1.00      0.33         1\n",
      "           4       0.70      0.75      0.72        28\n",
      "           5       0.89      0.53      0.67        32\n",
      "           6       0.92      1.00      0.96        11\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.50      0.50      0.50        10\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.17      1.00      0.29         1\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.73      0.76      0.74        21\n",
      "          15       0.56      0.50      0.53        10\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       1.00      0.50      0.67         2\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.36      0.18      0.24        22\n",
      "          22       0.25      0.50      0.33         4\n",
      "          23       0.29      0.25      0.27         8\n",
      "          24       0.33      0.50      0.40         2\n",
      "          25       1.00      0.55      0.71        11\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.56      0.45      0.50        20\n",
      "          30       0.33      1.00      0.50         1\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.67      0.41      0.51        29\n",
      "          33       0.00      0.00      0.00         0\n",
      "          35       0.15      0.29      0.20         7\n",
      "          36       0.75      1.00      0.86         9\n",
      "          37       0.87      0.83      0.85        24\n",
      "          38       0.75      0.86      0.80         7\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.50      0.40      0.44        10\n",
      "          41       0.73      0.89      0.80         9\n",
      "          42       0.75      0.69      0.72        13\n",
      "          44       0.00      0.00      0.00         0\n",
      "          46       0.71      0.40      0.51        30\n",
      "          47       0.87      0.72      0.79        18\n",
      "          48       0.70      0.74      0.72        19\n",
      "          49       0.82      0.82      0.82        11\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.60      0.60      0.60         5\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.06      0.25      0.10         4\n",
      "          54       0.67      0.46      0.55        13\n",
      "          55       0.77      0.61      0.68        59\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.71      0.57      0.63        30\n",
      "          58       0.00      0.00      0.00         0\n",
      "          60       0.79      0.73      0.76        15\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.59       500\n",
      "   macro avg       0.38      0.40      0.37       500\n",
      "weighted avg       0.69      0.59      0.62       500\n",
      "\n",
      "Accuracy : 59.200\n",
      "F1 Score: 0.624\n",
      "Confusion Matrix: \n",
      "[[ 1  0  0 ...  0  0  0]\n",
      " [ 0  1  0 ...  0  0  0]\n",
      " [ 0  0 21 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 11  1  1]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 3.7399 - accuracy: 0.0768 - val_loss: 3.4993 - val_accuracy: 0.2378\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 31s 481ms/step - loss: 3.5950 - accuracy: 0.1232 - val_loss: 3.3395 - val_accuracy: 0.0644\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 36s 559ms/step - loss: 2.8321 - accuracy: 0.3168 - val_loss: 2.4063 - val_accuracy: 0.4111\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 36s 564ms/step - loss: 1.7738 - accuracy: 0.5802 - val_loss: 2.0540 - val_accuracy: 0.5467\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 35s 544ms/step - loss: 1.2123 - accuracy: 0.7111 - val_loss: 1.9809 - val_accuracy: 0.5400\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         1\n",
      "           4       0.65      0.65      0.65        26\n",
      "           5       0.67      0.29      0.40        35\n",
      "           6       0.86      0.32      0.46        19\n",
      "           7       0.38      0.50      0.43         6\n",
      "           8       0.38      0.62      0.48         8\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.20      1.00      0.33         1\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.88      0.36      0.51        39\n",
      "          15       1.00      0.64      0.78        11\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         0\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.17      0.06      0.09        17\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.25      0.60      0.35         5\n",
      "          24       0.67      0.67      0.67         3\n",
      "          25       1.00      0.78      0.88         9\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.55      0.80      0.65        15\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.50      1.00      0.67         1\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.40      0.26      0.32        23\n",
      "          33       0.00      0.00      0.00         0\n",
      "          35       0.12      0.25      0.17         4\n",
      "          36       0.88      1.00      0.93         7\n",
      "          37       0.85      0.94      0.89        18\n",
      "          38       0.90      0.82      0.86        11\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.33      0.67      0.44         3\n",
      "          41       0.75      0.90      0.82        10\n",
      "          42       0.75      1.00      0.86         9\n",
      "          46       0.77      0.63      0.70        38\n",
      "          47       0.91      0.77      0.83        13\n",
      "          48       0.38      0.31      0.34        16\n",
      "          49       0.67      0.73      0.70        11\n",
      "          50       0.20      1.00      0.33         1\n",
      "          51       0.75      0.60      0.67        10\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.10      0.50      0.17         4\n",
      "          54       0.53      0.77      0.62        13\n",
      "          55       0.74      0.48      0.58        82\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.50      0.75      0.60        12\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.85      0.65      0.73        17\n",
      "          62       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.55       500\n",
      "   macro avg       0.38      0.41      0.37       500\n",
      "weighted avg       0.68      0.55      0.58       500\n",
      "\n",
      "Accuracy : 55.000\n",
      "F1 Score: 0.580\n",
      "Confusion Matrix: \n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 1  0 17 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  1 11  1]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 31s 481ms/step - loss: 3.7547 - accuracy: 0.0802 - val_loss: 3.4125 - val_accuracy: 0.3044\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 33s 513ms/step - loss: 3.5631 - accuracy: 0.1227 - val_loss: 3.3667 - val_accuracy: 0.0622\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 32s 506ms/step - loss: 2.5388 - accuracy: 0.3953 - val_loss: 2.2605 - val_accuracy: 0.5044\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 32s 505ms/step - loss: 1.5875 - accuracy: 0.6294 - val_loss: 1.9804 - val_accuracy: 0.5200\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 1.0508 - accuracy: 0.7474 - val_loss: 1.8367 - val_accuracy: 0.5444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.33      0.50      0.40         2\n",
      "           4       0.85      0.74      0.79        31\n",
      "           5       0.70      0.61      0.65        23\n",
      "           6       0.50      1.00      0.67         2\n",
      "           7       0.50      1.00      0.67         1\n",
      "           8       0.60      0.38      0.46         8\n",
      "           9       0.00      0.00      0.00         0\n",
      "          11       0.33      0.09      0.14        11\n",
      "          12       0.00      0.00      0.00         0\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.89      0.59      0.71        27\n",
      "          15       0.62      0.83      0.71         6\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       0.00      0.00      0.00         2\n",
      "          21       0.33      0.20      0.25        10\n",
      "          22       0.33      1.00      0.50         1\n",
      "          23       0.62      0.83      0.71         6\n",
      "          24       0.57      0.80      0.67         5\n",
      "          25       0.81      0.87      0.84        15\n",
      "          27       0.86      0.50      0.63        24\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.33      1.00      0.50         1\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.32      0.62      0.42        13\n",
      "          33       0.33      0.33      0.33         3\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.43      0.60      0.50        10\n",
      "          36       1.00      0.50      0.67         8\n",
      "          37       0.90      0.87      0.88        30\n",
      "          38       0.64      1.00      0.78         7\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.67      0.46      0.55        13\n",
      "          41       0.58      0.64      0.61        11\n",
      "          42       0.85      0.85      0.85        13\n",
      "          43       0.00      0.00      0.00         0\n",
      "          46       0.65      0.53      0.59        32\n",
      "          47       1.00      0.78      0.88        18\n",
      "          48       0.47      0.64      0.54        11\n",
      "          49       0.92      0.92      0.92        12\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.50      0.75      0.60         4\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.38      0.19      0.25        16\n",
      "          54       0.81      0.62      0.70        21\n",
      "          55       0.75      0.66      0.70        64\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.64      0.50      0.56        18\n",
      "          58       0.00      0.00      0.00         0\n",
      "          60       0.93      0.88      0.90        16\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.63       500\n",
      "   macro avg       0.41      0.43      0.40       500\n",
      "weighted avg       0.71      0.63      0.65       500\n",
      "\n",
      "Accuracy : 63.000\n",
      "F1 Score: 0.655\n",
      "Confusion Matrix: \n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  1 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 14  0  2]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 32s 495ms/step - loss: 3.7529 - accuracy: 0.0753 - val_loss: 3.5595 - val_accuracy: 0.0133\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 3.6034 - accuracy: 0.1109 - val_loss: 3.4913 - val_accuracy: 0.0822\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 33s 515ms/step - loss: 2.8886 - accuracy: 0.2946 - val_loss: 2.3986 - val_accuracy: 0.4378\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 32s 497ms/step - loss: 1.8200 - accuracy: 0.5709 - val_loss: 2.1495 - val_accuracy: 0.4733\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 32s 508ms/step - loss: 1.1859 - accuracy: 0.7158 - val_loss: 2.0112 - val_accuracy: 0.5156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.33      0.20         3\n",
      "           2       0.00      0.00      0.00         2\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.77      0.90      0.83        41\n",
      "           5       0.76      0.43      0.55        30\n",
      "           6       0.67      1.00      0.80         6\n",
      "           7       0.20      0.17      0.18         6\n",
      "           8       0.44      0.33      0.38        12\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.17      1.00      0.29         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.75      0.60      0.67        20\n",
      "          15       0.88      0.58      0.70        12\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         3\n",
      "          18       0.00      0.00      0.00         0\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.11      0.50      0.18         2\n",
      "          22       0.25      1.00      0.40         2\n",
      "          23       0.29      0.67      0.40         3\n",
      "          24       1.00      0.29      0.44        14\n",
      "          25       0.40      0.67      0.50         3\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.50      0.50      0.50        10\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.33      0.50      0.40         2\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.40      0.10      0.16        58\n",
      "          33       0.00      0.00      0.00         0\n",
      "          35       0.17      0.25      0.20         8\n",
      "          36       1.00      0.73      0.84        11\n",
      "          37       0.76      0.72      0.74        18\n",
      "          38       1.00      0.75      0.86         8\n",
      "          39       0.33      1.00      0.50         2\n",
      "          40       0.75      0.50      0.60         6\n",
      "          41       0.73      0.89      0.80         9\n",
      "          42       0.77      0.45      0.57        22\n",
      "          43       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.56      0.71      0.63        14\n",
      "          47       0.69      0.75      0.72        12\n",
      "          48       0.56      0.45      0.50        22\n",
      "          49       0.90      0.60      0.72        15\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.62      0.71      0.67         7\n",
      "          53       0.14      0.25      0.18         8\n",
      "          54       0.52      0.67      0.59        18\n",
      "          55       0.68      0.52      0.59        62\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.45      0.68      0.54        19\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.78      1.00      0.88         7\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.53       500\n",
      "   macro avg       0.34      0.37      0.32       500\n",
      "weighted avg       0.62      0.53      0.55       500\n",
      "\n",
      "Accuracy : 53.200\n",
      "F1 Score: 0.547\n",
      "Confusion Matrix: \n",
      "[[1 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 7 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 31s 488ms/step - loss: 3.7566 - accuracy: 0.0743 - val_loss: 3.5837 - val_accuracy: 0.0111\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 31s 486ms/step - loss: 3.5746 - accuracy: 0.1225 - val_loss: 3.2601 - val_accuracy: 0.3044\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 33s 512ms/step - loss: 2.7812 - accuracy: 0.3370 - val_loss: 2.4445 - val_accuracy: 0.4689\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 31s 486ms/step - loss: 1.7507 - accuracy: 0.5862 - val_loss: 2.2644 - val_accuracy: 0.4867\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 32s 494ms/step - loss: 1.1632 - accuracy: 0.7185 - val_loss: 2.1358 - val_accuracy: 0.5022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.00      0.00      0.00         0\n",
      "           4       0.93      0.36      0.51        76\n",
      "           5       0.50      1.00      0.67         9\n",
      "           6       0.82      0.90      0.86        10\n",
      "           7       0.33      0.50      0.40         2\n",
      "           8       0.43      0.60      0.50         5\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         2\n",
      "          13       0.50      1.00      0.67         1\n",
      "          14       0.90      0.61      0.73        44\n",
      "          15       0.62      0.50      0.56        10\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.50      1.00      0.67         2\n",
      "          19       0.00      0.00      0.00         1\n",
      "          21       0.11      1.00      0.20         1\n",
      "          22       0.00      0.00      0.00         0\n",
      "          23       0.07      1.00      0.12         1\n",
      "          24       0.00      0.00      0.00         0\n",
      "          25       0.92      0.92      0.92        12\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.50      0.31      0.38        13\n",
      "          28       0.00      0.00      0.00         0\n",
      "          30       0.00      0.00      0.00         1\n",
      "          32       0.18      1.00      0.31         4\n",
      "          33       0.00      0.00      0.00         0\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       1.00      0.86      0.92        14\n",
      "          37       1.00      0.48      0.65        31\n",
      "          38       1.00      0.75      0.86        12\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       0.17      0.11      0.13         9\n",
      "          41       0.71      0.62      0.67         8\n",
      "          42       0.67      0.73      0.70        11\n",
      "          43       0.00      0.00      0.00         0\n",
      "          46       0.73      0.52      0.60        31\n",
      "          47       0.67      0.83      0.74        12\n",
      "          48       0.53      0.62      0.57        13\n",
      "          49       0.95      0.68      0.79        28\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.22      0.50      0.31         4\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.71      0.59      0.65        17\n",
      "          55       0.69      0.50      0.58        66\n",
      "          56       0.00      0.00      0.00         0\n",
      "          57       0.56      0.64      0.60        28\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.92      0.85      0.88        13\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.56       500\n",
      "   macro avg       0.33      0.37      0.32       500\n",
      "weighted avg       0.75      0.56      0.62       500\n",
      "\n",
      "Accuracy : 56.400\n",
      "F1 Score: 0.615\n",
      "Confusion Matrix: \n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  3 27 ...  1  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 11  0  1]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "Epoch 1/5\n",
      "64/64 [==============================] - 32s 496ms/step - loss: 3.7574 - accuracy: 0.0733 - val_loss: 3.4277 - val_accuracy: 0.3178\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 32s 494ms/step - loss: 3.5914 - accuracy: 0.1269 - val_loss: 3.1765 - val_accuracy: 0.3333\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 31s 480ms/step - loss: 2.6469 - accuracy: 0.3756 - val_loss: 2.4678 - val_accuracy: 0.4444\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 32s 494ms/step - loss: 1.6317 - accuracy: 0.6131 - val_loss: 1.8707 - val_accuracy: 0.5311\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 32s 500ms/step - loss: 1.0717 - accuracy: 0.7422 - val_loss: 1.9683 - val_accuracy: 0.5111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.33      0.33      0.33         3\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.74      0.79      0.77        29\n",
      "           5       0.60      0.56      0.58        27\n",
      "           6       0.83      0.62      0.71         8\n",
      "           7       0.50      0.12      0.20         8\n",
      "           8       0.88      0.70      0.78        10\n",
      "           9       0.00      0.00      0.00         0\n",
      "          11       0.00      0.00      0.00         0\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.50      1.00      0.67         2\n",
      "          14       0.95      0.61      0.74        33\n",
      "          15       0.88      0.58      0.70        12\n",
      "          16       0.00      0.00      0.00         0\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.67      0.50      0.57         4\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.09      0.20      0.13         5\n",
      "          22       0.50      0.25      0.33         4\n",
      "          23       0.45      0.71      0.56         7\n",
      "          24       0.25      0.50      0.33         2\n",
      "          25       0.75      0.60      0.67        10\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.53      0.50      0.51        20\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       1.00      0.50      0.67         2\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.35      0.44      0.39        16\n",
      "          33       0.25      0.14      0.18         7\n",
      "          35       0.33      0.20      0.25         5\n",
      "          36       0.92      1.00      0.96        12\n",
      "          37       0.85      0.81      0.83        27\n",
      "          38       0.83      1.00      0.91         5\n",
      "          39       0.00      0.00      0.00         0\n",
      "          40       1.00      0.33      0.50        12\n",
      "          41       0.83      0.67      0.74        15\n",
      "          42       0.83      0.50      0.62        10\n",
      "          43       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       0.66      0.61      0.63        31\n",
      "          47       0.75      0.69      0.72        13\n",
      "          48       0.75      0.40      0.52        15\n",
      "          49       0.56      0.82      0.67        11\n",
      "          50       0.33      0.50      0.40         2\n",
      "          51       0.67      0.67      0.67         3\n",
      "          53       0.22      0.44      0.30         9\n",
      "          54       0.67      0.57      0.62        21\n",
      "          55       0.63      0.57      0.60        60\n",
      "          56       0.67      1.00      0.80         2\n",
      "          57       0.65      0.89      0.76        19\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.00      0.00      0.00         0\n",
      "          60       0.90      0.75      0.82        12\n",
      "          62       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.60       500\n",
      "   macro avg       0.42      0.39      0.39       500\n",
      "weighted avg       0.68      0.60      0.62       500\n",
      "\n",
      "Accuracy : 60.000\n",
      "F1 Score: 0.622\n",
      "Confusion Matrix: \n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 9 1]\n",
      " [0 0 0 ... 0 0 1]]\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 30s 470ms/step - loss: 3.7498 - accuracy: 0.0689 - val_loss: 3.4182 - val_accuracy: 0.0133\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 32s 507ms/step - loss: 3.5715 - accuracy: 0.1190 - val_loss: 3.1746 - val_accuracy: 0.3044\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 32s 503ms/step - loss: 2.5908 - accuracy: 0.3864 - val_loss: 2.1742 - val_accuracy: 0.5089\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 32s 503ms/step - loss: 1.5587 - accuracy: 0.6299 - val_loss: 1.9228 - val_accuracy: 0.5111\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 32s 499ms/step - loss: 1.0196 - accuracy: 0.7556 - val_loss: 1.8886 - val_accuracy: 0.5667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         3\n",
      "           2       0.12      0.50      0.20         2\n",
      "           4       0.80      0.80      0.80        40\n",
      "           5       0.67      0.64      0.65        22\n",
      "           6       0.60      1.00      0.75         3\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.75      0.55      0.63        11\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.00      0.00      0.00         0\n",
      "          11       0.43      0.60      0.50         5\n",
      "          12       0.00      0.00      0.00         0\n",
      "          14       0.77      0.65      0.71        26\n",
      "          15       0.88      0.74      0.80        19\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       1.00      1.00      1.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         0\n",
      "          21       0.12      0.05      0.07        20\n",
      "          22       0.17      1.00      0.29         1\n",
      "          23       0.44      1.00      0.62         4\n",
      "          24       0.25      1.00      0.40         1\n",
      "          25       0.93      0.93      0.93        14\n",
      "          26       0.50      1.00      0.67         1\n",
      "          27       0.50      0.60      0.55        10\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.00      0.00      0.00         0\n",
      "          30       0.75      1.00      0.86         3\n",
      "          31       0.00      0.00      0.00         0\n",
      "          32       0.50      0.78      0.61         9\n",
      "          33       0.20      1.00      0.33         1\n",
      "          35       0.40      0.40      0.40         5\n",
      "          36       1.00      0.78      0.88         9\n",
      "          37       0.93      0.78      0.85        18\n",
      "          38       0.75      0.86      0.80         7\n",
      "          39       0.00      0.00      0.00         1\n",
      "          40       0.44      0.50      0.47         8\n",
      "          41       0.75      0.60      0.67        10\n",
      "          42       0.80      0.44      0.57         9\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.00      0.00      0.00         0\n",
      "          46       0.65      0.54      0.59        28\n",
      "          47       1.00      0.68      0.81        22\n",
      "          48       0.50      0.46      0.48        13\n",
      "          49       0.93      0.74      0.82        19\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       0.71      0.71      0.71         7\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       0.29      0.20      0.24        25\n",
      "          54       0.71      0.62      0.67        16\n",
      "          55       0.67      0.56      0.61        64\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.60      0.65      0.63        23\n",
      "          58       0.00      0.00      0.00         0\n",
      "          60       0.71      0.91      0.80        11\n",
      "          62       0.33      0.33      0.33         3\n",
      "\n",
      "    accuracy                           0.61       500\n",
      "   macro avg       0.42      0.47      0.42       500\n",
      "weighted avg       0.67      0.61      0.63       500\n",
      "\n",
      "Accuracy : 61.200\n",
      "F1 Score: 0.630\n",
      "Confusion Matrix: \n",
      "[[ 2  0  0 ...  0  0  0]\n",
      " [ 0  1  0 ...  0  0  0]\n",
      " [ 0  0 32 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0 10  1]\n",
      " [ 0  0  0 ...  0  2  1]]\n",
      "Mean 0.62 Std 0.03\n",
      "Time: 1706.2459223270416 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "evaluate_lstm(seqs, seqs_mat, y_mat_2, 63)\n",
    "print(f'Time: {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. BERT Based Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.1. Label Encoding for both classes `class1` and `class2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COURSE CLASSES\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TTD': 0, 'TGU': 1, 'ACM': 2, 'TRS': 3, 'WTH': 4, 'FOD': 5, 'ENT': 6}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels_1 = df['class1'].unique()\n",
    "possible_labels_2 = df['class2'].unique()\n",
    "\n",
    "label_dict_1 = {}\n",
    "for index, possible_label in enumerate(possible_labels_1):\n",
    "    label_dict_1[possible_label] = index\n",
    "print('COURSE CLASSES')\n",
    "label_dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINE CLASSES\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'TTDSIG': 0,\n",
       " 'TTDOTH': 1,\n",
       " 'TGUHEA': 2,\n",
       " 'ACMOTH': 3,\n",
       " 'TRSTRN': 4,\n",
       " 'TGUBAN': 5,\n",
       " 'WTHTMP': 6,\n",
       " 'TGUNEI': 7,\n",
       " 'TTDSPO': 8,\n",
       " 'ACMAPA': 9,\n",
       " 'TRSOTH': 10,\n",
       " 'TRSAIR': 11,\n",
       " 'TRSROU': 12,\n",
       " 'TGUOTH': 13,\n",
       " 'ACMRES': 14,\n",
       " 'ACMBUN': 15,\n",
       " 'TRSCRS': 16,\n",
       " 'WTHDRC': 17,\n",
       " 'TRSRNT': 18,\n",
       " 'TGUTOP': 19,\n",
       " 'FODOTH': 20,\n",
       " 'TGUVIS': 21,\n",
       " 'FODAUT': 22,\n",
       " 'TTDTRI': 23,\n",
       " 'TGUPLN': 24,\n",
       " 'TRSTAX': 25,\n",
       " 'WTHOTH': 26,\n",
       " 'TRSBUS': 27,\n",
       " 'ACMHOT': 28,\n",
       " 'TGULUG': 29,\n",
       " 'FODBAK': 30,\n",
       " 'TTDSPA': 31,\n",
       " 'FODBRE': 32,\n",
       " 'TGUATT': 33,\n",
       " 'ENTCLB': 34,\n",
       " 'TGUAVE': 35,\n",
       " 'TGUTEL': 36,\n",
       " 'TGUCIG': 37,\n",
       " 'TTDSHP': 38,\n",
       " 'TRSTCD': 39,\n",
       " 'ACMBEA': 40,\n",
       " 'FODCOT': 41,\n",
       " 'TGUAPT': 42,\n",
       " 'TRSLIC': 43,\n",
       " 'TGULAU': 44,\n",
       " 'TTDGYM': 45,\n",
       " 'FODCAT': 46,\n",
       " 'FODBAR': 47,\n",
       " 'TGUHOL': 48,\n",
       " 'ENTFES': 49,\n",
       " 'TGURUL': 50,\n",
       " 'TGURES': 51,\n",
       " 'ACMCAR': 52,\n",
       " 'FODFMA': 53,\n",
       " 'ENTSHW': 54,\n",
       " 'TRSGAS': 55,\n",
       " 'WTHSNW': 56,\n",
       " 'ENTMUS': 57,\n",
       " 'ENTSPO': 58,\n",
       " 'TGUWEB': 59,\n",
       " 'TRSDRV': 60,\n",
       " 'FODFCA': 61,\n",
       " 'ENTOTH': 62}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('FINE CLASSES')\n",
    "label_dict_2 = {}\n",
    "for index, possible_label in enumerate(possible_labels_2):\n",
    "    label_dict_2[possible_label] = index\n",
    "label_dict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>class1_enc</th>\n",
       "      <th>class2_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the special things we (husband and me...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "      <td>special things husband day stay cape town</td>\n",
       "      <td>special things husband day stay cape town</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the companies which organize shark fe...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDOTH</td>\n",
       "      <td>companies organize shark feeding events scuba ...</td>\n",
       "      <td>company organize shark feed events scuba divers</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is it safe for female traveller to go alone to...</td>\n",
       "      <td>TGU</td>\n",
       "      <td>TGUHEA</td>\n",
       "      <td>safe female traveller go alone cape town</td>\n",
       "      <td>safe female traveller go alone cape town</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the best places around Cape Town for ...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "      <td>best places around cape town safari</td>\n",
       "      <td>best place around cape town safari</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the best places to stay for a family ...</td>\n",
       "      <td>ACM</td>\n",
       "      <td>ACMOTH</td>\n",
       "      <td>best places stay family stay away nightlife</td>\n",
       "      <td>best place stay family stay away nightlife</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the train services that travels from ...</td>\n",
       "      <td>TRS</td>\n",
       "      <td>TRSTRN</td>\n",
       "      <td>train services travels cape town oudtshoorn</td>\n",
       "      <td>train service travel cape town oudtshoorn</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are the best places to spend about 2 week...</td>\n",
       "      <td>ACM</td>\n",
       "      <td>ACMOTH</td>\n",
       "      <td>best places spend weeks relaxing honeymoon sou...</td>\n",
       "      <td>best place spend weeks relax honeymoon south a...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Can we use travellers cheques and credit cards...</td>\n",
       "      <td>TGU</td>\n",
       "      <td>TGUBAN</td>\n",
       "      <td>use travellers cheques credit cards cape town</td>\n",
       "      <td>use travellers cheque credit card cape town</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Is it warm enough to swim in early September i...</td>\n",
       "      <td>WTH</td>\n",
       "      <td>WTHTMP</td>\n",
       "      <td>warm enough swim early september cape town</td>\n",
       "      <td>warm enough swim early september cape town</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are the best beaches for shelling in Cape...</td>\n",
       "      <td>TTD</td>\n",
       "      <td>TTDSIG</td>\n",
       "      <td>best beaches shelling capetown</td>\n",
       "      <td>best beach shell capetown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text class1  class2  \\\n",
       "0  What are the special things we (husband and me...    TTD  TTDSIG   \n",
       "1  What are the companies which organize shark fe...    TTD  TTDOTH   \n",
       "2  Is it safe for female traveller to go alone to...    TGU  TGUHEA   \n",
       "3  What are the best places around Cape Town for ...    TTD  TTDSIG   \n",
       "4  What are the best places to stay for a family ...    ACM  ACMOTH   \n",
       "5  What are the train services that travels from ...    TRS  TRSTRN   \n",
       "6  What are the best places to spend about 2 week...    ACM  ACMOTH   \n",
       "7  Can we use travellers cheques and credit cards...    TGU  TGUBAN   \n",
       "8  Is it warm enough to swim in early September i...    WTH  WTHTMP   \n",
       "9  What are the best beaches for shelling in Cape...    TTD  TTDSIG   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0          special things husband day stay cape town   \n",
       "1  companies organize shark feeding events scuba ...   \n",
       "2           safe female traveller go alone cape town   \n",
       "3                best places around cape town safari   \n",
       "4        best places stay family stay away nightlife   \n",
       "5        train services travels cape town oudtshoorn   \n",
       "6  best places spend weeks relaxing honeymoon sou...   \n",
       "7      use travellers cheques credit cards cape town   \n",
       "8         warm enough swim early september cape town   \n",
       "9                     best beaches shelling capetown   \n",
       "\n",
       "                                          lemmatized  class1_enc  class2_enc  \n",
       "0          special things husband day stay cape town           0           0  \n",
       "1    company organize shark feed events scuba divers           0           1  \n",
       "2           safe female traveller go alone cape town           1           2  \n",
       "3                 best place around cape town safari           0           0  \n",
       "4         best place stay family stay away nightlife           2           3  \n",
       "5          train service travel cape town oudtshoorn           3           4  \n",
       "6  best place spend weeks relax honeymoon south a...           2           3  \n",
       "7        use travellers cheque credit card cape town           1           5  \n",
       "8         warm enough swim early september cape town           4           6  \n",
       "9                          best beach shell capetown           0           0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class1_enc'] = df.class1.replace(label_dict_1)\n",
    "df['class2_enc'] = df.class2.replace(label_dict_2)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.2. Train and Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_val_1, y_train_1, y_val_1 = train_test_split(df.index.values, \n",
    "                                                  df.class1_enc.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df.class1_enc.values)\n",
    "\n",
    "X_train_2, X_val_2, y_train_2, y_val_2 = train_test_split(df.index.values, \n",
    "                                                  df.class2_enc.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=42, \n",
    "                                                  stratify=df.class2_enc.values)\n",
    "\n",
    "df['data_type'] = ['not_set']*df.shape[0]\n",
    "\n",
    "df.loc[X_train_1, 'data_type'] = 'train'\n",
    "df.loc[X_val_1, 'data_type'] = 'val'\n",
    "\n",
    "df.loc[X_train_2, 'data_type'] = 'train'\n",
    "df.loc[X_val_2, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class2</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>class2_enc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class1</th>\n",
       "      <th>class1_enc</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ACM</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ENT</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>train</th>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">FOD</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>train</th>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TGU</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>1038</td>\n",
       "      <td>1038</td>\n",
       "      <td>1038</td>\n",
       "      <td>1038</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TRS</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>train</th>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TTD</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>968</td>\n",
       "      <td>968</td>\n",
       "      <td>968</td>\n",
       "      <td>968</td>\n",
       "      <td>968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">WTH</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>train</th>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  class2  preprocessed_text  lemmatized  \\\n",
       "class1 class1_enc data_type                                                \n",
       "ACM    2          train       612     612                612         612   \n",
       "                  val         108     108                108         108   \n",
       "ENT    6          train       184     184                184         184   \n",
       "                  val          32      32                 32          32   \n",
       "FOD    5          train       442     442                442         442   \n",
       "                  val          79      79                 79          79   \n",
       "TGU    1          train      1038    1038               1038        1038   \n",
       "                  val         182     182                182         182   \n",
       "TRS    3          train       860     860                860         860   \n",
       "                  val         151     151                151         151   \n",
       "TTD    0          train       968     968                968         968   \n",
       "                  val         172     172                172         172   \n",
       "WTH    4          train       146     146                146         146   \n",
       "                  val          26      26                 26          26   \n",
       "\n",
       "                             class2_enc  \n",
       "class1 class1_enc data_type              \n",
       "ACM    2          train             612  \n",
       "                  val               108  \n",
       "ENT    6          train             184  \n",
       "                  val                32  \n",
       "FOD    5          train             442  \n",
       "                  val                79  \n",
       "TGU    1          train            1038  \n",
       "                  val               182  \n",
       "TRS    3          train             860  \n",
       "                  val               151  \n",
       "TTD    0          train             968  \n",
       "                  val               172  \n",
       "WTH    4          train             146  \n",
       "                  val                26  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['class1', 'class1_enc', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class1</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>class1_enc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class2</th>\n",
       "      <th>class2_enc</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ACMAPA</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>train</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ACMBEA</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">40</th>\n",
       "      <th>train</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACMBUN</th>\n",
       "      <th>15</th>\n",
       "      <th>train</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WTHOTH</th>\n",
       "      <th>26</th>\n",
       "      <th>val</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">WTHSNW</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">56</th>\n",
       "      <th>train</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">WTHTMP</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>train</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text  class1  preprocessed_text  lemmatized  \\\n",
       "class2 class2_enc data_type                                                \n",
       "ACMAPA 9          train        25      25                 25          25   \n",
       "                  val           4       4                  4           4   \n",
       "ACMBEA 40         train         4       4                  4           4   \n",
       "                  val           1       1                  1           1   \n",
       "ACMBUN 15         train        45      45                 45          45   \n",
       "...                           ...     ...                ...         ...   \n",
       "WTHOTH 26         val          20      20                 20          20   \n",
       "WTHSNW 56         train         6       6                  6           6   \n",
       "                  val           1       1                  1           1   \n",
       "WTHTMP 6          train        17      17                 17          17   \n",
       "                  val           3       3                  3           3   \n",
       "\n",
       "                             class1_enc  \n",
       "class2 class2_enc data_type              \n",
       "ACMAPA 9          train              25  \n",
       "                  val                 4  \n",
       "ACMBEA 40         train               4  \n",
       "                  val                 1  \n",
       "ACMBUN 15         train              45  \n",
       "...                                 ...  \n",
       "WTHOTH 26         val                20  \n",
       "WTHSNW 56         train               6  \n",
       "                  val                 1  \n",
       "WTHTMP 6          train              17  \n",
       "                  val                 3  \n",
       "\n",
       "[124 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['class2', 'class2_enc', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.3. BertTokenizer and Encoding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Install Torch by: `conda install -c pytorch pytorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Install Transformers by: `conda install -c conda-forge transformers` or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Install Transformers by: `pip3 install transformers` or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Install Transformers by: `conda install -c huggingface transformers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Install `sacremoses`: `pip3 install sacremoses`  - still PackageNotFound error for sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Install `sacremoses`: `conda install pytorch torchvision cudatoolkit=10.0 -c pytorch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `conda create --name hf-transformers -c conda-forge transformers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `https://www.gitmemory.com/issue/huggingface/tokenizers/685/826136101`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `conda install -c huggingface tokenizers=0.10.1 transformers=4.6.1` - this resoved error - versioning error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### To solve this error, try the following code lines : `ModuleNotFoundError: No module named 'transformers.models.bert.tokenization_bert'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### `pip uninstall transformers`\n",
    "###### `pip install transformers==3.5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### After restarting the jupyter notebook, error vanished after the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from transformers import BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/singhabahu/anaconda3/envs/python38test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2016: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)\n",
    "                                          \n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].lemmatized.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].lemmatized.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train_1 = torch.tensor(df[df.data_type=='train'].class1_enc.values)\n",
    "labels_train_2 = torch.tensor(df[df.data_type=='train'].class2_enc.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val_1 = torch.tensor(df[df.data_type=='val'].class1_enc.values)\n",
    "labels_val_2 = torch.tensor(df[df.data_type=='val'].class2_enc.values)\n",
    "\n",
    "dataset_train_1 = TensorDataset(input_ids_train, attention_masks_train, labels_train_1)\n",
    "dataset_val_1 = TensorDataset(input_ids_val, attention_masks_val, labels_val_1)\n",
    "dataset_train_2 = TensorDataset(input_ids_train, attention_masks_train, labels_train_2)\n",
    "dataset_val_2 = TensorDataset(input_ids_val, attention_masks_val, labels_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.4. BERT Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict_1),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.5. Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 3\n",
    "\n",
    "dataloader_train_1 = DataLoader(dataset_train_1, \n",
    "                              sampler=RandomSampler(dataset_train_1), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation_1 = DataLoader(dataset_val_1, \n",
    "                                   sampler=SequentialSampler(dataset_val_1),\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "dataloader_train_2 = DataLoader(dataset_train_2, \n",
    "                              sampler=RandomSampler(dataset_train_2), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation_2 = DataLoader(dataset_val_2, \n",
    "                                   sampler=SequentialSampler(dataset_val_2),\n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.6. Optimizer & Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "                  \n",
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train_1)*epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.7. Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels, dict):\n",
    "    label_dict_inverse = {v: k for k, v in dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063190288d1644438353ebe9cc8f7485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=1417.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singhabahu/anaconda3/envs/python38test/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:117: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/finetuned_BERT_epoch_1.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d6e4befdba95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'/content/finetuned_BERT_epoch_{epoch}.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nEpoch {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38test/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38test/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python38test/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/finetuned_BERT_epoch_1.model'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# device = torch.device(\"cuda:0\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "\n",
    "    for batch in dataloader_val:\n",
    "\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "start = time.time()\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train_1, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.to(device)\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "\n",
    "        # optimizer = optim.Adam(model.parameters())\n",
    "        optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "        # optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        for state in optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.cuda()\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "\n",
    "\n",
    "    torch.save(model.state_dict(), f'/content/finetuned_BERT_epoch_{epoch}.model')\n",
    "\n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train_1)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation_1)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')\n",
    "    \n",
    "    print(f'Time: {time.time() - start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.9. Loading and Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results for `class1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f03cb3379138>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                       \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dict_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                       \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                       output_hidden_states=False)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BertForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict_1),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('/content/finetuned_BERT_epoch_1.model', map_location=torch.device('cuda:0')))\n",
    "model.load_state_dict(torch.load('/content/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))\n",
    "\n",
    "start = time.time()\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "print(f'Time: {time.time() - start} seconds')\n",
    "    \n",
    "fine_pred = [np.argmax(p) for p in predictions]\n",
    "fine_gt = [np.argmax(p) for p in true_vals]\n",
    "\n",
    "val_acc = accuracy_score(fine_gt, fine_pred)*100\n",
    "f1 =  f1_score(fine_pred, fine_gt, average='weighted')\n",
    "\n",
    "print(classification_report(fine_gt,fine_pred))\n",
    "print('Accuracy : %.3f' % val_acc)\n",
    "print('F1 Score: %.3f' % f1)\n",
    "cm = confusion_matrix(fine_gt, fine_pred)\n",
    "print(\"Confusion Matrix: \\n{}\".format(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results for `class2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict_2),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load('/content/finetuned_BERT_epoch_1.model', map_location=torch.device('cuda:0')))\n",
    "model.load_state_dict(torch.load('/content/finetuned_BERT_epoch_1.model', map_location=torch.device('cpu')))\n",
    "\n",
    "start = time.time()\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "print(f'Time: {time.time() - start} seconds')\n",
    "    \n",
    "fine_pred = [np.argmax(p) for p in predictions]\n",
    "fine_gt = [np.argmax(p) for p in true_vals]\n",
    "\n",
    "val_acc = accuracy_score(fine_gt, fine_pred)*100\n",
    "f1 =  f1_score(fine_pred, fine_gt, average='weighted')\n",
    "\n",
    "print(classification_report(fine_gt,fine_pred))\n",
    "print('Accuracy : %.3f' % val_acc)\n",
    "print('F1 Score: %.3f' % f1)\n",
    "cm = confusion_matrix(fine_gt, fine_pred)\n",
    "print(\"Confusion Matrix: \\n{}\".format(cm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38test",
   "language": "python",
   "name": "python38test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
